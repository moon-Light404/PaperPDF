### 联邦学习安全聚合
1.联邦学习中，各个设备在本地训练模型，然后将更新的模型参数或梯度传输到中央服务器进行聚合，但是客户端提交的梯度会泄露其本地数据集的信息，从而安全聚合得到应用，目前的研究大多数适用于HFL。

2.安全聚合一般有几个方面和要求：
- 保证梯度的隐私，防止梯度泄露
- 对退出(掉线)的用户具有鲁棒性
- 通信效率，开销成本优化、考虑

3.目前主流的思路：
- 一次性密钥
- 同态加密
- 安全多方计算(允许多个参与方在不暴露各自私密输入的情况下进行计算，准确性和安全性最高，但是效率不高和协议难设计，理论上可以实现任意计算函数)
  - OT
  - 混淆电路
  - ZKP零知识证明
- 差分隐私(LDP、GDP)
- 基于掩码的聚合(成对掩码、非成对掩码聚合lightSecAgg)，大多数方案中对掉线用户采用的是秘密共享恢复掩码种子。

之前看的方案中采用掩码方式的比较多，大部分都是在17年谷歌提出的经典双掩码方案，在此基础上进行改进安全性和提升效率。
优化协议通信拓扑结构、梯度量化加密
掩码密钥轮次复用(Flamingo,2023S&P)，消除以前协议的每轮设置需要，轻量级弹性协议
为了防止恶意服务器篡改也有一些方案专注于聚合结果的验证(可验证聚合 VerSA、VOSA、Verifynet，比如同态哈希、可验证秘密分享、Pederson承诺)

4.MPC协议-安全聚合

ABY2(看了多次)、ABY3(看了一点)、SPDZ(了解，需要很多前置知识)
Secure3(安全三方计算下常用的函数和协议、加性秘密共享)
近年很多目光开始向在安全聚合的基础上过滤恶意梯度(防御梯度鲁棒攻击)，MPC-安全聚合成为一个不得不考虑的选项。大致上是将中央服务器的信任分发到两台或三台服务器上，客户将梯度采用MPC的手段(算术共享、布尔共享)分发给若干个服务器，这几个服务器执行MPC协议进行梯度计算、恶意梯度筛选(范数增强防御)等。

方案：RoFL(单服务器聚合、零知识证明来规范边界)、Pro+(双服务器聚合)、ELSA(双服务器，2023 S&P，只是大致了解了怎么做的，由于后面放假没花很多时间去研究里面用到的一些前置方案的思路技术)这些论文都是看过的，但是理解不够深刻，协议较复杂。

#### 纵向联邦学习推理攻击
VFL相比HFL研究要少很多。VFL的区别是参与方共享相同的样本、但拥有不同的特征，只有一个参与方有样本的标签(active party,其余叫做passive party)。每个参与方传递是中间结果(HFL对应局部数据)，分为model spliting和without model spliting。大部分推理攻击是根据服务器或active party发送回来的局部梯度(对参与方k的本地模型$\theta_k$的梯度$\frac{\partial_{H_{ik}}}{\partial{\theta_k}}$)。

很多针对VFL方案是从经典的集中式ML/DL中迁移过去的，经典的梯度泄露论文DLG(模拟、最小化梯度距离恢复数据)、iDLG(根据梯度符号判断标签)

最近看了一些标签推理攻击的方案：
> (based on sample-level or batched-level gradients)
direct label inference(源于idlg)
Norm Scoring
Direction Scoring
残差重建(逻辑回归二分类推理标签)
梯度反演、成员推理攻击 


基于训练好的模型：模型补全(model completion，分为主动和被动)、

>防御(目前关注的点)：梯度压缩、梯度随机选择、梯度裁剪、梯度离散化
对抗性重建、噪声正则化、距离相关性
MARVELL(样本级梯度添加优化噪声防御NS和DS攻击)、标签伪装方法(CAE、DCAE)


大多数方案专注的点都是减少梯度中所包含原始数据标签的信息量或相关程度，也需要在实用性和隐私性之间进行权衡。

特征推理攻击指的是拥有标签的那一方active party推断passive party的特征$x_p$，这块还没怎么看。防御这块差分隐私应用比较多，但是可能比较困难。


