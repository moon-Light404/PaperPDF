推荐：<a href="https://differential-privacy.cn/2-Basic-Terms/Formalizing-differential-privacy/Formalizing-differential-privacy-Overview.html">The Algorithmic Foundations of Differential Privacy</a>

<a href="https://zhuanlan.zhihu.com/p/139114240">参考</a>

差分隐私
**定义**
差分隐私（Differential Privacy，简称DP）是一种用于在数据分析中保护个人隐私的技术。它的核心思想是在发布的数据中添加一定量的随机噪声，这样即使攻击者拥有除了一个人的全部信息，也无法确定该个人是否存在于原始数据集中。差分隐私提供了一种量化的隐私保障，允许数据的统计分析同时限制个人信息的泄露。

形式化定义是通过比较两个相邻的数据集(差别仅在一个数据点)上执行同一个随机化算法输出结果的分布差异来给出的，如果两个分布足够接近，那么算法被认为提供了差分隐私。

**公式化**：
算法$M$提供了$\epsilon-差分隐私$，如对于任两个相邻的数据集$D$和$D'$(它们之间只有一个数据点的差异)，以及对所有$M$可能的输出集合$S$，有：
$$Pr[M(x) \in S] \leq e^{\epsilon} \ Pr[M(x') \in S]$$

其中 $\Pr[\mathcal{M}(x) \in S]$ 表示当算法 $\mathcal{M}$ 应用于数据集 $x$ 时，输出结果落在集合 $S$ 中的概率。参数 $\epsilon > 0$ 称为隐私预算或隐私损失参数，它控制了隐私保护的强度：$\epsilon$ 越小，隐私保护越强，但可能会牺牲数据的实用性。

理解：算法的目的是使这两个分布尽可能地接近，衡量两个分布$Y,Z$的差异可以使用KL散度：
$$D(Y||Z)=\mathbb{E}_{y\sim Y}[ln \frac{Pr[Y=y]}{Pr[Z=y]}]$$
两个分布差距最大情况下被bound住，最大散度MAx-Divergence，使得它小于$\epsilon$：
$$D_{\infty}(Y||Z)=max_{S \in Supp(Y)}[ln\frac{Pr[Y \in S]}{Pr[Z \in S]}]=max_{y \in Y}[ln \frac{Pr[Y=y]}{Pr[Z=y]}] \leq \epsilon$$
这个公式化简一下就变成了差分隐私对应的公式的内容了。