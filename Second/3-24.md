### 《Residue-based Label Protection Mechanisms in Vertical Logistic Regression》
出处：2022 8th International Conference on Big Data Computing and Communications (BigCom)
本文首先提出了一种标签推理攻击方法来研究垂直逻辑回归模型的潜在隐私泄露问题。具体来说，我们发现攻击者可以利用残差变量来推断私有标签，残差变量是通过求解由**局部数据集和接收到的解密梯度构建的线性方程组**来计算的。为了解决这一问题，提出了三种保护机制，即加性噪声机制、乘性噪声机制和利用局部差分隐私和同态加密技术的混合机制，以防止攻击并提高垂直逻辑回归模型的鲁棒性。实验结果表明，加性噪声机制和乘性噪声机制都能在不降低模型测试精度的情况下实现有效的标签保护，混合机制在不降低测试精度的情况下实现标签保护，验证了保护技术的有效性和高效性。

#### Logistic Regression
数据集$T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$
逻辑回归是输出空间$Y \in \{0,1\}$的二元监督机器学习模型，非线性映射函数为
$$f(\mathbf{W})=\sigma(\mathbf{W}^Tx),\sigma(z)=\frac{1}{1+e^{-z}}$$
目标函数：
$$\mathcal{L}=-\frac{1}{N}y_i \ log(f(x_i))+(1-y_i)log(1-f(x_i))+\lambda\Omega(\mathbf{W})$$
梯度：
$$\frac{\partial \mathcal{L}}{\partial \mathbf{W}}=-\frac{1}{N}\sum_{i=1}^N(y_i-f(x_i))x_i=-\frac{1}{m}\sum_{i=1}^m(y_i-h_{\theta}(x_i))x_j^i$$
其中$x_j^i$表示第$i$个数据中的第$j$个特征，中间的代表每个数据的真实值-预测值，$m$表示数据个数。

#### 系统模型和威胁模型
Bob是active party,拥有部分数据特征和真实标签，Alice是passive party只拥有部分特征。两方协作训练一个纵向联邦回归模型，不需要可信第三方的帮助，特征分别表示为$X^A$和$X^B$。

**威胁模型**
Alice试图推断Bob中拥有的真实私有标签，通过传输的中间消息实现，它拥有的知识包括：
- 私有数据集$D^A$
- 特征空间$X^{d_A}$
- 它的特征$d^A$
- 与$X^{d_A}$相关的部分模型参数$W^A$

#### 问题阐述
在每次迭代中，Bob选择一小批量$B$计算相应的损失和预测值，并将残差residue  $r_i=y_i-f(x_i)$加密后$\lang r_i \rang$发送给Alice，Alice可以在加密残基上计算加密梯度，并通过Bob解密的梯度update更新其本地模型。当Ailce接收到加密的残差向量$\lang r_i \rang$和解密后的梯度$g^A=\frac{\partial(L)}{\partial(\theta_A)}$，Alice构建一下线性方程组：

该方程组有唯一解，无需解密密文获得残差的真值，当激活函数是sigmod有$0 < f(x_i) < 1$，然后有当$r_i>0 \rightarrow y_i=1$和$r_i < 0\rightarrow y_i =1$。

本文最后提出了局部差分隐私和加性同态加密来设计残差保护机制防止Bob的私有标签泄露。差分隐私这块接触比较少，后续了解一下。

本周还在继续做等保项目相关的东西。

