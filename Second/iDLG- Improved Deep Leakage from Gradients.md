## 摘要
人们普遍认为，在协作学习和联邦学习等分布式学习系统中，共享梯度不会泄露私有训练数据。最近，Zhu 等人。 [1]提出了一种方法，表明可以从公开共享的梯度中获取私人训练数据。在梯度深度泄漏（DLG）方法中，他们在共享梯度的监督下合成虚拟数据和相应的标签。然而，DLG 在收敛和一致地发现真实标签方面存在困难。在本文中，我们发现共享梯度肯定会泄漏真实标签。我们提出了一种简单但可靠的方法来从梯度中提取准确的数据。特别是，我们的方法肯定可以提取与 DLG 不同的真实标签，因此我们将其命名为改进的 DLG (iDLG)。我们的方法对于任何通过单热标签上的交叉熵损失训练的可微模型都是有效的。我们从数学上说明了我们的方法如何从梯度中提取真实标签，并凭经验证明了相对于 DLG 的优势。

<!-- ![20240520150523](https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/20240520150523.png) -->