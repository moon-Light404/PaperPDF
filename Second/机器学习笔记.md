### 概率论相关
#### 协方差、相关性
- 方差用来衡量单个随机变量的离散程度，协方差用来刻画两个随机变量的相似程度，方差计算公式为：
$$\sigma^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2$$
- 协方差计算公式:
$$\sigma(x,y)=\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})$$(样本协方差)
$$Cov(X,Y)=\sum_{i=1}^N\frac{(X_i-u_x)(Y_i-u_y)}{N}$$

- 协方差矩阵：衡量多个随机变量的相似度的协方差矩阵。
$$
\left[
\begin{matrix}
\sigma(x_1,x_1) & \cdots &\sigma(x_1,x_d) \\
\cdots & \cdots & \cdots\\
\sigma(x_d,x_1) & \cdots & \sigma(x_d,x_d) \\
\end{matrix}
\right]
$$
其中，对角线上的元素为各个随机变量的方差，非对角线上的元素为两两随机变量之间的协方差，矩阵为对称矩阵，大小为$d \times d$。

- 相关性(皮尔逊相关系数)
$$r = \frac{{\sum (X_i - \bar{X})(Y_i - \bar{Y})}}{{\sqrt{\sum (X_i - \bar{X})^2 \sum (Y_i - \bar{Y})^2}}}=\frac{Cov(X,Y)}{\sigma(X)\sigma(Y)}$$


### 混淆矩阵


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-22.png">
</img>
</div>
</img>
</div>

- TP:真阳类，真实类别是正类，预测结果也是正类(预测对)
- FN:假阴类，真实类别是正类，但预测结果是负类(错误)
- FP:假阳类，真实类别是负类，但预测结果是正类(错误)
- TN:真阴类，真实类别是负类，预测结果是负类(预测对)

**(预测对/错，预测结果)**


> 分类指标

- 精确率(Accuracy)：模型精度。模型识别正确的个数/样本总个数
  $$Accuracy=\frac{TP+TN}{TP+FN+FP+TN}$$
- 准确率(Precision)：模型识别为正类的样本中，真正为正类的样本所占的比例。一般情况下，查准率越高，说明模型的效果越好。
$$Precision = \frac{TP}{TP+FP}$$
- 召回率(Recall)：又称为查全率，召回率表现出在实际正样本中，分类器能预测出多少。
  $$Recall=\frac{TP}{TP+FN}$$

- F1-score：<a href="https://zhuanlan.zhihu.com/p/161703182">参考</a>
适用于数据集出现类别不平衡的情况，它是精确率和召回率的调和平均数(平衡精确率和召回率)，综合评价模型性能。

$$F1score=\frac{2 P \times R}{P+R}$$

#### ROC曲线
ROC曲线用于评估二分类问题的模型性能，通过绘制不同阈值下的真正例率(TPR)和假正例率(FPR)来展示分类器性能，曲线中的每个点对应不同的阈值(区分0和1的阈值)，即对应不同的混淆矩阵。

<div align="center" >
<img width=400px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-23.png">
</img>
</div>

$$TFP=\frac{TP}{P}=\frac{TP}{TP+FN}$$
$$FPR=\frac{FP}{N}=\frac{FP}{FP+TN}$$

AUC(Area Under Curve)值：ROC与x坐标轴围成的面积，面积越大越好。
AUC-ROC代表一个模型对正负例的区分能力(不放过一个)，它的值在0~1之间，越大代表模型性能越好。
- 当AUC的值接近1时，代表模型效果很好；
- 当AUC的值为0的时代表模型总是颠倒黑白，把好的说成坏的，坏的说成好的
- 当值为0.5的时候可认为模型知识随机做出判断，不具备区分能力。



### 信息与交叉熵
**信息量**
事件发生的概率越低，该事件发生对应的信息量就越高，反之发生概率越高的事件信息量越低。
信息量公式：$I(x_0) = -log_2P(x)$

**熵**
熵越大，代表着这个系统的不确定性越高、混乱程度越大，也可以表示为无损编码事件信息的最小平均编码长度。**信息熵**用于衡量整个事件空间包含的平均信息量，为信息的平均期望。
$$Entropy =-\sum_i P(i)log_2 P(i) -最小平均编码长度 $$其中，$P(i)$是第$i$个状态的可能性。
在信息论中，熵（Entropy）是衡量随机变量不确定性的一个度量。对于一个离散概率分布 $P$，其熵 $H(P)$ 定义为：

$$
H(P) = -\sum_{i} P(x_i) \log_b P(x_i)
$$

其中，$x_i$ 表示可能的输出，$P(x_i)$ 表示输出 $x_i$ 的概率，$\log_b$ 是以 $b$ 为底的对数函数。在信息论中，常常使用以 2 为底的对数，这时候熵的单位是比特（bit）。

如果随机变量 $X$ 的概率分布为 $P$，那么 $X$ 的熵记作 $H(X)$，并且有 $H(X) = H(P)$。

这个公式的含义是，如果你要用最短的编码来编码一个随机变量，那么**平均每个符号需要的比特数**就是这个随机变量的熵。


### KL散度 <a href="https://zhuanlan.zhihu.com/p/438129018">参考</a>
KL散度(Kullback-Leibler Divergence)是用来度量两个概率分布相似度的指标，它作为经典损失函数被广泛地用于聚类分析与参数估计等机器学习任务中。
**KL散度的定义**
假设对随机变量$\xi$，存在两个概率分布$P,Q$，如果$\xi$为离散随机变量，定义从$P$到$Q$的KL散度为：
$$\mathbb{D}_{KL}(P||Q)=\sum_iP(i)ln \frac{P(i)}{Q(i)}$$
如果$\xi$为随机连续变量，$P$到$Q$的KL散度为：
$$\mathbb{D}_{KL}(P||Q)=\int_{-\infty}^{\infty}p(x)ln\frac{p(x)}{q(x)}dx$$

关系：
$$H(P,Q)=\mathbb{D}_{KL}(P||Q)+H(P)$$

1、非负性
$\mathbb{D}_{KL}(P||Q) \geq 0,\mathbb{D}_{KL}=0当且仅当P=Q$

2、仿射不变性
假设$\mathbf{y}=a\mathbf{x}+b$，那么：
$$\mathbb{D}_{KL}(P(\mathbf{x})||Q(\mathbf{x}))=\mathbb{D}_{KL}(P(\mathbf{y})||Q(\mathbf{y}))$$

3、$\mathbb{D}_{KL}(P||Q) \neq\mathbb{D}_{KL}(Q||P)$

4、$\mathbb{D}_{KL}(P||Q)$在一定条件下可以趋于无穷。

**KL散度的应用**
- 独立性度量:我们可以用KL散度来度量两个随机变量x,y
的独立性：
  $I(x,y)=\mathbb{D}_{KL}(P=P(x,y)||Q=P(x)P(y))=\sum_{x,y}p(x,y)ln \frac{p(x,y)}{p(x)p(y)}$

如果$x,y$统计独立，那么$I(x,y)=0$


---



**交叉熵**
交叉熵可以看作是把来自一个分布$q$的消息使用另一个分布$p$的最佳编码传达的平均长度，或者某个分布的信息量在另一个分布的信息熵。
交叉熵的作用：
分类问题损失函数：
- 在机器学习和深度学习中，交叉熵常用作分类问题的损失函数。对于分类任务，我们通常使用 softmax 函数将模型的输出转换为概率分布，然后使用交叉熵来衡量**模型输出的概率分布与真实标签之间的差异**。
- 交叉熵损失函数能够有效地衡量模型在分类任务中的预测误差，帮助模型学习正确的分类边界。

信息论中的应用：
- 在信息论中，交叉熵用于衡量两个概率分布之间的差异。当两个概率分布之间的交叉熵较小时，表示它们之间的相似度较高；反之，交叉熵较大时，表示它们之间的差异性较大。



$$H(p,q)=\sum_xp(x)log_2(\frac{1}{q(x)})=-\sum_xp(x)log_2q(x)$$


**二分类**：
激活函数为 sigmmod $\rightarrow f(z)=\frac{1}{1+e^{-z}}$

损失函数为$L(\mathbf{w})=-\frac{1}{N}\sum_{i=1}^N[y_ilogf(x_i)+(1-y_i)log(1-f(x_i))]$

简写成$$C=-\frac{1}{N}\sum_{i=1}^N[y_ilna+(1-y_i)ln(1-a)]$$
其中$z=wx+b,a=\sigma(z)$,$N$表示样本数量。
- $y_i$表示样本$i$的label，正类为1，负类为0
- $p_i$表示样本$i$预测为正类的概率

**多分类**：
$$L=\frac{1}{N}\sum_i L_i=-\frac{1}{N}\sum_i\sum_{c=1}^My_{ic}log(p_{ic})$$
- M 类别的数量
- $y_{ic}$ 符号函数(0,1)如果样本$i$的真实类别等于$c$取1，否则取0
- 观测样本$i$属于类别$c$的预测概率

|预测 |真实标签向量 |是否正确 |
|---|---|---|
|0.3 0.3 0.4|[0 0 1]|对|
|0.3 0.4 0.3|[0 1 0]|对|
|0.1 0.2 0.7|[1 0 0]|错|

sample1 loss：$0 \times log0.3+0 \times log0.3+1\times log0.4=0.91$
sample2 loss：0.91
samole3 loss：2.30
average: L = 1.37


多分类：
激活函数为softmax $$\sigma(\mathbf{z})_j=\frac{e^{z_j}}{\sum_{k=1}^Ke^{z_k}}$$

损失函数为：
$$C=-\sum_{i=1}^k y_i \ lna$$
其中$a=\sigma(z)$.

----

### 决策树模型
参考 <a href="https://zhuanlan.zhihu.com/p/26760551?utm_campaign=shareopn&utm_medium=social&utm_psn=1754179712279371776&utm_source=wechat_session">决策树链接</a>
决策树：从根节点开始一步步走到叶子节点(决策)
所有数据最终都会落到叶子节点，既可做分类也可以做回归。决策树是一个树结构，其中每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值上的输出，表示每个特征属性有几个值就有几个分支。
使用决策树进行决策的过程就是**从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果**。

- 结点和有向边组成
- 结点有内部结点和叶结点两种类型
- 内部节点表示一个特征，叶结点表示一类

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image18.png">
</img>
</div>

**重点问题：如何选择特征？**
决策树的关键就是选择最优划分属性，希望划分后，分支结点的“纯度”越来越高，根据“纯度”的衡量方法不同，也导致了学习算法的不同，如ID3算法和C4.5算法。

#### ID3算法
“信息熵”是度量样本集合不确定度(纯度)的常用指标，ID3算法采用**最大化信息增益**来对结点进行划分。信息熵是代表随机变量的复杂度(不确定度)，条件熵代表在某一条件下，随机变量的不确定度，如某个属性有三个值，在确定的值下对应的结果的不确定性。
- 当前集合中$D$中第$k$类样本所占的比例为$pk$，则$D$的信息熵定义为：
$$Ent(D)=-\sum_{k=1}^{|y|}p_klog_2 \ p_k$$
- 离散属性$a$有个可能的取值$\{a_1,a_2,\cdots,a_v\}$，属性$a$上取值为$a_v$的样本集合，记为$D_v$.
- 用属性$a$对样本集合$D$进行划分获得“信息增益”
条件熵:$$Ent(D|a)=\sum_{v-1}^V\frac{|D^v|}{|D|}Ent(D^v)$$
$$Gain(D,a)=Ent(D)-\sum_{v-1}^V\frac{|D^v|}{|D|}Ent(D^v)$$
<u>计算每个条件熵的加权平均</u>
如果选择一个特征后，信息增益最大，那么就选取这个特征。
缺点：我们从上面求解信息增益的公式中，其实可以看出，信息增益准则其实是对可取值数目较多的属性有所偏好！因为每一个样本的编号都是不同的（由于编号独特唯一，条件熵为0了，每一个结点中只有一类，纯度非常高啊），也就是说，来了一个预测样本，你只要告诉我编号，其它特征就没有用了，这样生成的决策树显然不具有泛化能力。

#### C4.5算法
C4.5解决ID3的这个缺点，如果属性的分类很多，也就是分叉超多，那么该属性下的样本就很少，此时的信息增益非常高，ID3认为这个属性适合用作划分，但取值较多的属性用作划分依据时，它的泛化能力弱，没法对新样本有效预测。C4.5依靠“信息增益率”划分样本。

属性$a$的固有值，当属性$a$可取值数量$V$越多，那$IV(a)$的值就越大
$IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}log_2\ \frac{|D^v|}{|D|}$
信息增益率计算：
$$GainRatio(D,a)=\frac{Gain(D,a)}{IV(a)}$$
注意：这里不是无脑选择最高的信息增益率，而是启发式地选择：先从划分出的属性中找到信息增益高于平均的那些属性，然后再从这些属性中选信息增益率最高的。


#### CART(classification and regression tree)决策树
ID3中使用了信息增益选择特征，增益大优先选择。C4.5中，采用信息增益率选择特征，减少因特征值多导致信息增益大的问题。CART分类树算法使用基尼系数选择特征，基尼系数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）相反。

> 基尼系数

数据集$D$的纯度可用基尼值来度量
$$Gain(D)=\sum_{i=1}^n\ p(x_i) \cdot(1-p(x_i)) =1-\sum_{i=1}^n \ p(x_i)^2$$
其中，$p(x_i)$是分类$x_i$出现的概率，$n$是分类的数目。$Gain(D)$反映了**从数据集D中随机抽取两个样本，其类别标记不一致的概率**。因此，Gini(D)越小，则数据集D的纯度越高。
对于样本$D$，个数为$|D|$，根据特征$A$是否取某一可能值$a$，把样本$D$分为两部分$D_1$和$D_2$，所以CART分类树算法建立起来的是二叉树，不是多叉树。

在属性A的条件下，样本D的基尼系数定义为
$$GiniIndex(D|A=a)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)$$

$$Gini\_index(D,a)=\sum_{v=1}^V\frac{|D^v|}{D}Gini(D^v)$$

在候选属性集合A中，选择那个使得划分后的基尼系数值最小的属性作为最优划分属性
$a_*=argmin_{a \in A}\ Gini\_index(D,a)$

决策树递归过程：

- 停止条件：1）没有更多特征选择了；2）数据集本身就已经分类好了，纯数据集
- 特征选择：根据自己选择的度量标准来选择特征；
- 递归调用主函数并根据选择特征不断地生成子树，直到停止条件

---

决策树是一个非常容易发生过拟合的模型，因为如果没有任何限制，在生成的阶段，它将会穷尽所有的特征，直到停止条件。这时叶子节点的数目最多，而叶子节点越多则越容易发生过拟合缺少泛化能力。如下图所示，右图就是未剪枝后的过拟合情况，显然对于新的数据集效果将会很差。
<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-19.png">
</img>
</div>


剪枝、防止过拟合：<a href="https://mp.weixin.qq.com/s?__biz=MzUzODYwMDAzNA==&amp;mid=2247485708&amp;idx=1&amp;sn=139938fb9bba9f707dca9df8d284b41d&amp;chksm=fad47e01cda3f717c0b86868fbfbfd4ffd9549a103832291d69e28c059ab42a2ab68073a8e92&amp;scene=21#wechat_redirect">剪枝</a>




### 正则化总结


### 极大似然估计

#### 贝叶斯公式

$$P(A|B)=\frac{P(B|A)\cdot P(A)}{P(B)}$$
条件概率：$P(AB)=P(A|B)P(B)=P(B|A)P(A)$

- $P(A|B)$ 是后验概率。
- $P(B|A)$ 是给定事件(A)发生时，观测到新证据(B)的概率，称为似然性。
- $P(A)$ 是先验概率。
- $P(B)$ 是新证据(B)的概率，也称为证据的边缘概率。 

极大似然估计（MLE）是一种在统计学中用于**从样本数据中估计概率模型参数的方法**。
**先验概率（Prior Probability）**：先验概率，通常表示为(P(A))，是在观测数据之前对某一事件或假设发生概率的判断。它基于以往的经验、已有的知识或专家的判断。先验概率是贝叶斯分析的起点，它代表了我们在考虑新信息之前对事件发生可能性的先有认识。

**后验概率（Posterior Probability）**：

举个例子，如果我们想估计一个硬币扔在空中然后落地时正面朝上的概率，而我们对这个硬币一无所知，那么我们可能会基于对“公平硬币”的了解，假设这个概率（先验概率）是0.5。后验概率，通常表示为(P(A|B))，是在考虑了新的证据或信息(B)之后，对事件(A)发生的概率进行更新后的评估。后验概率是贝叶斯定理的核心，通过先验概率、似然性以及证据的概率，结合新的观测数据来计算得到。继续硬币的例子，如果我们扔了这个硬币10次，发现它9次正面朝上，那么我们可以使用贝叶斯定理来更新我们对这个硬币正面朝上概率的认识。在这种情况下，后验概率会倾向于认为这个硬币正面朝上的概率可能大于0.5。

#### 基本原理

假设有一组观测数据 \( X=\{x_1,x_2,...,x_n\} \)，这些数据来自一个参数为 \( \theta \) 的概率分布，但 \( \theta \) 是未知的。MLE 的目标是找到参数 \( \hat{\theta} \) 的估计，使得在该参数下，观测到数据集 \( X \) 的概率（似然）最大。

#### 似然函数

对于这个函数$P(x|\theta)$,$x$表示某个具体的数据，$\theta$表示模型的参数；

- 如果$\theta$是已知确定的，$x$是变量，这个函数叫做概率函数，它描述对于不同的样本点$x$，其出现概率是多少
- 如果$x$是已知确定的，$\theta$是变量，这个函数叫做似然函数(likelihood function), 它**描述对于不同的模型参数，出现$x$这个样本点的概率是多少**。

对于独立同分布的观测数据，似然函数可以表示为：

\[ L(\theta; X) = \prod_{i=1}^n f(x_i;\theta) \]

其中，\( L(\theta; X) \) 是在参数 \( \theta \) 下观测到数据 \( X \) 的似然，\( f(x_i;\theta) \) 是在参数 \( \theta \) 下观测到数据 \( x_i \) 的概率。

#### 对数似然

为了简化计算，通常使用对数似然：

\[ \log L(\theta; X) = \sum_{i=1}^n \log f(x_i;\theta) \]

#### 优化问题

极大似然估计的目标是解决以下优化问题：

\[ \hat{\theta} = \arg\max_{\theta} \log L(\theta; X) \]

#### 应用

MLE 是一种非常通用的方法，可应用于多种概率模型，包括但不限于正态分布、泊松分布、二项分布以及各类回归模型。

#### 逻辑回归的最大似然估计

令逻辑回归的模型为$h_0(x;\theta)，则可以将其视为类1的后验概率$，所以有：
$p(y=1|x;\theta)=\psi(t)=\frac{1}{1+e^{-\theta^T}\cdot X_b}$  
$p(y=0|x;\theta)=1-\psi(t)=\frac{e^{-{\theta^T \cdot X_b}}}{1+e^{-\theta^T}\cdot X_b}$

也可以写成：
$p(y|x;\theta)=h_0(x;\theta)^y(1-h_0(x;\theta))^{1-y}$
当$y$取1时，$p(y|x;\theta)=h_0(x;\theta)$表示当前$x_i$预测为1的概率；当$y$取0时，$p(y|x;\theta)=1-h_0(x;\theta)$表示当前$x_i$预测为0的概率。其中$h_0(x;\theta)$表示样本预测为正类的概率。

### ML中的动量

指数加权移动平均---> 动量

对于时间序列$[x_0,x_1,\cdots,x_t]$
有[$\hat{x_0},\hat{x_1},\cdots,\hat{x_t}]$
其中，$\hat{x}=\gamma\hat{x_{t-1}}+(1-\gamma)x_t$
也就是说，时刻 t 的估计值由t-1时刻的估计值和时刻t的观测值加权平均得到。越早观测数据的占比越少，并且是成指数级别下降。

$$\hat{x_t}=(1-\gamma)x_t+\gamma\hat{x_{t-1}}+(1-\gamma)^2x_{t-2}+\cdots+(1-\gamma)^{n-1}x_{t-n+1}$$
时刻$t$的估计值是对最近n= 1 / (1-γ)个时间步的观测值的加权平均，并且时间距当前时刻越近的权重越高，时间越远的权重越低；γ=0时只使用当前时刻的观测值更新估计序列，γ 越接近 1 其使用的过去时刻越多。 

公式：
$v_t \leftarrow \gamma v_{t-1}+\eta_t \Delta f_t$
$x_t \leftarrow x_{t-1} - v_t$
直观形式：
$v_t \leftarrow \gamma v_{t-1} + (1-\gamma)\frac{\eta_t \Delta f_t}{1- \gamma}$
主要公式：
$v_t = \beta v_t + (1-\beta) g_{\theta}$
$\theta = \theta - \eta \cdot v_t$
其中$g_\theta$是损失函数的梯度。
