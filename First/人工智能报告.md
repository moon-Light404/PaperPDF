## 1. 研究背景

### 1.1 研究目标及任务
&emsp;&emsp;机器学习，特别是深度学习，在科学、商业和政府的许多领域取得了重大突破，如制造业、交通运输业、金融和医疗保健。集中学习主要有助于在大规模数据集上取得这些显著的成功。随着边缘计算[3]和物联网[^4,5]等现代技术的普及，机器学习的计算方式发生了巨大变化。在许多现实场景中，数据自然分布，并由不同的组织/用户拥有。由于不同组织的竞争、数据隐私安全以及行政法规等原因，几乎不可能跨国家和机构上传数据进行集中学习。
&emsp;&emsp;为了利用分布式机密数据集，Google的研究人员提出了联邦学习的概念[7]。联邦学习使多个参与者能够在不共享数据的情况下协作构建联合机器学习模型，即无需将私有数据上传到集中式服务器或在参与者之间交换数据，从而允许解决数据隐私和数据安全等关键问题。然而，在这个框架中存在潜在的数据泄漏;甚至私有数据也保留在本地参与者中。联邦学习可能会泄露四种主要类型的信息:1)成员信息泄漏，2)意外特征泄漏，3)原始数据类代表的泄露[10]，4)原始数据泄漏[11,12]。最后一种类型的数据泄露对于隐私敏感的参与者来说是最不可接受的。先前的研究已经提出了一种利用梯度深度泄漏算法重构私有训练数据集原始数据的可能方法[11,12]。在这种情况下，一个自然的问题是如何开发一种保护隐私的分布式机器学习方法，同时避免在传输和聚合过程中梯度的潜在信息泄露?基于密码学的方法吸引了最多的兴趣，因为它们旨在通过将信息从可读状态转换为几乎无意义的状态来处理数据隐私、完整性和身份验证问题。具体而言，安全多方计算(MPC)[13]提供了一种通用原语，使分布式各方能够在不泄露其私有输入和输出的情况下共同计算任意功能[14]，因此自然适合于无信任各方之间的隐私保护模型聚合。
&emsp;&emsp;它以一种安全的方式解决了协作计算的问题，从而将局部模型拆分并转换为多个秘密共享。聚合模型是通过在参与者之间交换这些秘密份额来计算的，遵循精心设计的MPC协议。因此，没有任何一方拥有足够的秘密共享片段来重建任何特定的本地模型，从而保护本地模型不泄露给某些方，因此聚合服务器是适用的。另一方面，可加性秘密共享MPC协议[23]通常要求每个参与者生成m个本地模型的秘密共享，并将其分发给所有计算节点，其中m表示分布式学习参与者的总数。考虑到大多数情况下潜在参与者的数量很大，标准MPC在参与者之间生成、传输和计算秘密共享时，不可避免地会导致大量的本地计算和通信成本。
&emsp;&emsp;我们的目标是改进或提出一种优化MPC方案，能够降低客户端、服务器之间的通信和计算开销，同时保证MPC再隐私保护、安全聚合和模型准确性方面的优点。也能够成功抵御梯度泄露攻击DLG。并在后期进行一系列实验，对真实数据集进行训练和攻击实验来验证我们的结果。


### 1.2 国内外研究现状
&emsp;&emsp;近年来，随着机器学习(ML)算法的日益普及和对数据隐私的日益关注，不同的数据所有者(如移动设备或云服务器)共同解决机器学习问题，即训练ML模型，同时保护其数据隐私的场景引起了学术界和工业界的极大关注。在这方面，联邦学习(FL)[1]被提出用于实现增强隐私的分布式机器学习方案，并已广泛应用于物联网(IoT)，医疗保健，计算机视觉和推荐等场景。由于上述优点，MPC已被广泛应用于联邦学习框架中，用于保护隐私的模型聚合。CrypTen和OpenMined为PyTorch上构建的神经网络模型提供了基于mpc的联邦学习。然而，它们对整个系统的MPC开销和性能评估提供了非常有限的研究。Google对其实际MPC协议进行了计算和通信复杂性分析，并在大量移动设备上进行了实验评估[25]。[26]中提出了一个两阶段的支持mpc的联邦学习框架来减少通信开销并且通过选择不串通的委员会成员进行安全模型聚合，提高了系统的可扩展性。与上述研究不同的是，本文研究了复杂深度学习模型的网络结构，然后仅在关键神经网络层上应用基于MPC的隐私保护模型聚合。

&emsp;&emsp;梯度的信息泄漏[11,27,28]对分布式机器学习的工作方式产生了重大影响，特别是对于多方协作学习。在经典的分布式机器学习中，参与者通常信任服务器，并将他们的本地模型作为纯文本发送到服务器进行聚合。然而，当服务器成为一个好奇的服务器时，这种直接的信息交换步骤留下了在服务器上重建原始图像的可能性。Lyn等[29]对联邦学习的威胁模型以及中毒攻击和推理攻击进行了研究。

&emsp;&emsp;举一个简单的例子，我们考虑[^11]中提出的框架。它假设本地参与者遵循标准协议规则，并将梯度作为纯文本传输到服务器。服务器接收到本地客户端的梯度后，初始化输入$(x)$和标签$(y)$。恶意服务器根据虚拟输入$(x, y)$计算虚拟梯度，并计算虚拟梯度与受害者计算的梯度之差。接下来，服务器通过标准的基于梯度的方法更新虚拟输入和标签，并在虚拟梯度等于实际梯度时停止。因此，当batch大小为1时，攻击者可以重建与ground truth图像相同或非常相似的图像[10]。然而，DLG数据提取的收敛速度较慢，不能持续获得准确的真值标签。Zhao等[12]改进了DLG方法，从分布式学习系统的共享梯度中窃取数据和相应的标签。

### 1.3 研究思路及创新点
&emsp;&emsp;安全多方计算可以让多个参与方在不暴露各自私密输入的情况下进行协作计算，而不用公开或共享各自的私有数据。加性秘密分享MPC协议[^23]通常要求每个参与者生成$m$个本地模型的本地共享，并将其分发给其他所有节点，$m$表示分布式学习参与者的总数。考虑到大多数情况下潜在参与者的数量很大，标准MPC在参与者之间生成、传输和计算秘密共享时，不可避免地会导致大量的本地计算和通信成本。本文提出了一种部分加密的MPC解决方案，通过加密容易受到隐私保护攻击的模型参数(梯度)的关键部分，而不是在整个局部模型上应用MPC进行安全聚合。具体来说，只有第一层本地模型使用MPC策略加密，其余部分直接发送到集中式节点。这种解决方案大大减少了MPC带来的额外计算和通信开销，同时保留了MPC在隐私保护和模型准确性方面的优点。

### 1.4 研究意义与应用价值
&emsp;&emsp;联邦学习正处于蓬勃发展的阶段，安全性是其可以广泛使用的重要门槛，现有的联邦学习方案设计容易受到内部或者外部攻击者的攻击，这些攻击可能会威胁数据隐私和系统的鲁棒性。虽然安全多方计算可以保证联邦学习最终聚合训练的准确率，但是对整个模型进行MPC的范式处理会导致很大的计算和通信开销，通过创新性地处理单层梯度，在提高联邦学习聚合效率的同时保证了性能。
&emsp;&emsp;联邦学习系统不仅可能受到外部恶意攻击者的威胁，还可能面临内部参与方的潜在风险。我们的研究从威胁模型的角度出发，针对威胁如不可靠的梯度聚合服务器，提供了有效的防御手段。这有助于联邦学习系统更好地抵御内外部威胁，保障系统的整体安全性。这可能对一些实际生活中的大型联邦学习系统有所启发，从而节省一些不必要的资源浪费。优化的梯度信息选择策略和加密方案，有望在实际应用中显著减小梯度分享时的加密计算开销。这对于提高梯度分享的效率，降低通信开销，使得联邦学习在大规模部署和实际应用中更为可行。在联邦学习领域推动更加健康、可靠、高效的发展，为解决实际场景中的数据合作与隐私保护难题贡献有力的解决方案。
## 2. 研究内容
下面我们对整体的方案进行一个基本的概述。首先简述下问题背景。在联邦学习中，我们的目标是在数据$\mathcal{X}=\{\mathbf{X_1},\mathbf{X_2},\cdots,\mathbf{X_m}\}$上学习一个联合模型$\mathcal{M}_f$，这些数据分别位于$m$个分布式本地节点或设备$\{\mathcal{P_1},\mathcal{P_2},\cdots,\mathcal{P_m}\}$。在模型训练或推理的过程中，出于数据隐私保护的考虑，不允许数据离开本地节点，然而，模型$\mathcal{M}_f$的推理精度期望非常接近在$\mathcal{X}$中所有数据的组合上训练的模型$M_s$的推理精度。此外，不同节点上的数据可能具有不同的分布，这使得联邦学习更具有挑战性。
### 2.1 总体研究思路
**基于部分同态加密MPC的联邦学习**
在这项工作中，提出了一种部分同态加密的MPC(PEMPC)方法加密权值并训练联合模型，如图1所示。在这个系统中，$m$个参与者具有相同的神经网络架构，借助服务器模型聚合协同学习联合模型。一个典型的假设是参与者是诚实的，而服务器是诚实但好奇的。为了防止参与者的数据信息泄露到服务器，我们没有将任何参与者的整个模型发送到服务器。具体来说，将局部模型$\mathcal{G}_i$的梯度分为两种类型，分别为$(Type \ A,\mathcal{G}_i^A)$和$(Type \ B,\mathcal{G}_i^B)$，分别对应图中的虚线和实线。因此，将模型的权值参数分成Type A$(\mathcal{W}_i^A)$和Type B$(\mathcal{W}_i^B)$。



<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image28.png">
</img>
</div>

基于部分加密的MPC分布式机器学习的训练过程包含以下步骤：
- Step1：每个参与者$\mathcal{P}_i$根据子集的数据集$\mathbf{X_i}$在本地计算模型$\mathcal{M}_f$的梯度，记作$\mathcal{G}_i$。
- Step2：每个参与者$\mathcal{P}_i$生成A类梯度的秘密共享，并将其发送给本地其他参与者。
- Step3：每个参与者$\mathcal{P}_j$从其他本地参与者获得A类梯度的秘密份额$\mathcal{G}_1^A,\mathcal{G}_2^A,\cdots,\mathcal{G}_m^A$，然后$\mathcal{P}_j$将这些秘密份额汇总起来取代$\mathcal{G}_j^A$的值。
- Step4：每个参与者$\mathcal{P}_i$将A和B类梯度$\mathcal{G}_i^A$和$\mathcal{G}_i^B$一起发送给服务器。
- Step5：服务器将来自本地参与者的梯度聚合为
$$\mathcal{G}^A=\frac{1}{m}\mathcal{G}_i^A$$
和
$$\mathcal{G}^B=\frac{1}{m}\mathcal{G}_i^B$$
- Step6：服务器返回聚合结果给参与者。
- Step7：每个参与者$\mathcal{P}_i$更新本地模型为
$$\mathcal{W}=\mathcal{W}+ \alpha\mathcal{G}$$，其中$\alpha$是学习率。
以上步骤迭代进行，直至达到终止条件，完成整个训练过程。终止条件可以是达到最大训练epoch数、损失函数收敛或其他用户自定义的条件。框架中的神经网络架构可以是任何一种深度神经网络架构，如LeNet-5、VGG-16、ResNet-152和DenseNet-121。




### 2.2 技术路线
#### 2.2.1 联邦学习
联邦学习是一种分布式机器学习范式，其目的在于利用分布在各数据拥有方的数据，在保护数据隐私的前提下进行机器学习模型的训练。训练过程中，训练所需的信息或参数在各参与方或服务器之间传递，但数据不传递。本文采用横向联邦学习，在横向联邦学习中，每个参与方拥有相同的数据特征和标签，但拥有不同的数据样本。横向联邦学习的训练流程如下图所示。


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-29.png">
</img>
</div>
FedAvg[文献]算法是一种常用的联邦学习算法，用于在分布式环境中进行模型训练和聚合。该算法由Google在2016年提出，它能够在保护参与方隐私的同时进行模型训练和聚合。因为参与方的训练数据不离开本地，只有模型参数进行交互和聚合，从而避免了数据泄露的风险。此外，FedAvg还能够适应参与方数据的异质性，因为每个参与方可以在本地根据自身的数据进行训练。

#### 2.2.2 神经网络
&emsp;&emsp;神经网络也称为人工神经网络，是一种模仿生物神经网络的数学模型。一个神经网络最简单的结构包括输入层、隐藏层和输出层，每一层有多个神经元，每个神经元有不同的权重，上一层的神经元在激活函数处理后映射到下一层，  最终经过输出层输出结果。这里我们简单介绍下实验所用的卷积神经网络LeNet5,如图所示。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-30.png">
</img>
</div>


它的结构如下：
1）卷积层 1 (C1)：使用 6 个$5 \times 5$的卷积核，输出 6 个特征图，每个特征图的大小为 $28 \times 28$。
2）汇聚层 1 (S2)：使用 $2 \times 2$ 的最大汇聚，输出 6 个 $14 \times 14$ 的特征图。
3）卷积层 2 (C3)：使用 16 个 $5 \times 5$ 的卷积核，输出 16 个特征图，每个特征图的大小为 $10 \times 10$。
4）汇聚层 2 (S4)：使用 $2 \times 2$ 的最大汇聚，输出 16 个 $5 \times 5$ 的特征图。
5）全连接层 (F5)：包含 120 个神经元。
6）全连接层 (F6)：包含 84 个神经元。
7）输出层：包含 10 个神经元，对应于 10 个数字类别。
&emsp;&emsp;全连接层中，每个输入神经元都与每个输出神经元相连接，其中用到了$Relu$激活函数以增加网络输出的非线性因素。$Relu$函数的公式如下。
$$RELU(x)=max(0,x) $$
&emsp;&emsp;;当输入$x \geq 0$时输出不变，当输入$x \leq 0$时将输出为0，可以在一定程度上缓解神经网络训练时梯度消失的问题，有助于快速收敛模型。神经网络大部分是对模型的损失函数进行优化，不断降低损失函数的值来优化改进模型参数，以交叉熵为例，计算公式如下：
$$H(p,q)=-\sum_{i=1}^np(x_i)log(q(x_i)) $$
其中，$p$表示数据标签$one-hot$形式的数组的值，$q$表示预测概率结果的值。

#### 2.2.3 安全多方计算
&emsp;&emsp;接下来阐述如何使用安全MPC来聚合A类梯度$\mathcal{G}_1^A,\mathcal{G}_2^A,\cdots,\mathcal{G}_m^A$。安全MPC是密码学技术的一种，其目的是让参与者能够使他们在保持输入的秘密性的同时，共同计算一个函数，一个典型的秘密共享MPC协议如图所示。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-31.png">
</img>
</div>


&emsp;&emsp;在方法的第2步，每个参与者的A类梯度被拆分成$(m-1)$份秘密分享$\mathcal{D}_{i1}^A,{D}_{i2}^A,\cdots,{D}_{i(i-1)}^A,{D}_{i(i+1)}^A,\cdots,{D}_{im}^A$，它们组合起来就形成了原始的$\mathcal{G}_i^A$。在这项工作中，使用了加性秘密共享MPC协议。在第3步中，$P_j$收到的A类梯度的分享$\{D_{ij}^A\}_{i=1,i\neq j}^m$，并且计算模型聚合的初始结果为
$$\mathcal{D}_j^A= \sum_{i=1,i\neq j}^mD_{ij}^A$$
并且将其替换成$\mathcal{G}_j^A=D_j^A$。
&emsp;&emsp;在方法的第5步，服务器将根据聚合的秘密共享进行梯度聚合，即$\mathcal{G}_1^A,\mathcal{G}_2^A,\cdots,\mathcal{G}_m^A$，得到的汇总结果如式(1)所示。MPC的结果是通过对步骤3和步骤5分别进行两阶段的秘密分享求和得到的。

#### 2.2.4 梯度泄露攻击(DLG)
&emsp;&emsp;最近的研究[文献，DLG]发现，通过简单地在多个客户端之间交换神经网络模型梯度而不是原始数据，在分布式机器学习中仍然无法防止隐私泄露。诚实但好奇的服务器可以通过优化过程从获得的梯度中恢复私人数据。大致原理如图所示。


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-32.png">
</img>
</div>

&emsp;&emsp;本质上，DLG和其他现有的梯度反装攻击试图解决优化问题。利用在某个步骤$t$从参与者$k$接收到的目标梯度$\nabla W: \nabla_t^k=\frac{\partial \mathcal{L}_{grad}(F_w(x^*),y^*)}{\partial w}$，攻击者可以在该训练步骤总窃取带有标签$(x_t^k,y_t^k)$的输入。为了做到这一点，攻击者首先生成具有与目标数据相同大小的输入和标签$(x',y')$的随机伪输入，然后攻击者导出伪梯度$\nabla W'=\frac{\partial\mathcal{L}_grad(F_w(x'),y')}{\partial w}$。通过将虚拟数据发送到在参与者之间共享的机器学习模型$F_w$中，根据虚拟数据来确定模型权重；第二步用基于梯度的方法更新伪数据$(x',y')$，其中损失函数是伪梯度与给定梯度之间的距离$\mathbb{D}=\parallel \nabla W - \nabla W'\parallel ^ 2$。通过迭代这些步骤，虚拟数据$(x',y')$将移动得更接近目标训练数据，目标匹配为
$$x',y' = {arg \ min}_{x',y'} \ \mathbb{D}(\nabla W, \nabla W')$$
当整个优化过程完成后，私有的数据(样本，标签)就会被恢复。


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-33.png">
</img>
</div>



### 2.3 结果与讨论

#### 2.3.1 PEMPC阻止恢复训练数据
&emsp;&emsp;如前所述，服务器可能是诚实但好奇的[2]。服务器可以使用深度梯度泄露(DLG)来恢复所有参与者的原始训练集。可以看到$P_i$的第一层隐藏层的梯度是基于输入数据$\mathbf{X}_i$和第二隐藏层反向传播的结果计算的。因此，将第一个隐藏层加密为梯度类型$A$，以防止训练数据被恢复。
将第一层隐藏层的权重参数记为$W \in \mathbb{R}^{d \times n}$，偏差记为$b$，可以得到输入数据点$x$的第一层为：
$$y=f(z);\ z=Wx+b$$
其中$f(\cdot)$是激活函数比如经典的$sigmod，RELU$。通过使用DLG或iDLG，如果参与者只加密第一隐藏层的权重参数，服务器可以恢复$y$的准确结果。就算$f(\cdot)$是绝对单调的，可以精确地得到$z$，但是在只知道$z$的情况下是无法恢复出式中的$x$的。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-34.png">
</img>
</div>


#### 2.3.2 实验
&emsp;&emsp;我们通过在一个具有10个本地参与者和1个中央服务器的系统上进行本地模拟实验，使用Pytorch深度学习框架和LeNet5卷积神经网络在Mnist和Cifar10数据集上进行测试。
**梯度泄露攻击DLG** 
&emsp;&emsp;如上节所述，我们实现了DLG攻击的代码，如下图所示，optimizer优化的目标是伪造的梯度和标签，首先我们要将类别标签转换成one-hot-label，每轮使用模型训练伪造数据获得输出，计算预测结果与伪输入的导数，计算伪梯度与真实梯度之间的距离$grad\_diff$，对其反向传播求导。并在每10轮输出一次该值，观察变化情况。然后我们对两个数据集测试两张图片的运行结果如下所示。



<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-35.png">
</img>
</div>


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-36.png">
</img>
</div>

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-37.png">
</img>
</div>
&emsp;&emsp;我们将用户的本地模型的第一层隐藏层拆分给10个用户，先随机生成和第一层参数相同维度的矩阵9个，那么第10个直接用第一层隐藏层的参数减去这9个矩阵的和即可。让每个客户端本地模型的第一层清零，然后加上其余客户给他的分享股份和当作第一层的模型。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-38.png">
</img>
</div>

**预测精度的比较**
使用LeNet5对Mnist和Cifar10图像数据集进行分类，在训练和测试中研究了损失和准确度曲线，三种处理方式“NonMPC、MPC、PEMPC”分别对应标准分布式方法(不使用MPC)、完全MPC和部分MPC，模型的初始化、优化方法和学习率都设置为相同。我们设置全局轮次50轮，客户端本地训练轮次5轮，批处理大小64，学习率为0.01。实验结果图如下。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-39.png">
</img>
</div>


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-40.png">
</img>
</div>


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-41.png">
</img>
</div>


<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-42.png">
</img>
</div>


## 3. 总结与展望s
工作内容
主要贡献
创新点
不足



[^4]:
[^5]: