# <center>联邦学习中的隐私保护聚合调查

### 摘要
近年来，随着联邦学习(FL)算法的日益普及和对个人数据隐私的日益关注，隐私保护联邦学习(PPFL,Privacy-Preserving Federated Learning )引起了学术界和工业界的广泛关注。实用的PPFL通常允许多个参与者单独训练他们的机器学习模型，然后以保护隐私的方式聚合以构建全局模型。因此，隐私保护聚合协议(PPAgg,Privacy-Preserving Aggregation)作为PPFL中的关键协议受到了广泛的关注。本文对当前隐私保护聚合的前言进展和相关技术进行了梳理和分类，如双掩码、同态加密、差分隐私、安全多方计算、可信执行环境等方案技术。分析了联邦学习不同场景和设置下的聚合方案的优缺点，另外还讨论了支持PPAgg的开源FL框架，最后，强调了将PPAgg应用于FL系统以及PPAgg与其他技术结合以进一步提高安全性的重要挑战和未来的研究方向。

关键词 联邦学习 隐私保护 聚合 同态加密 安全多方计算

## 1 引言
近年来，随着机器学习(ML)算法的日益普及和对数据隐私的日益关注，不同的数据所有者(如移动设备或云服务器)共同解决机器学习问题，即训练ML模型，同时保护其数据隐私的场景引起了学术界和工业界的极大关注。在这方面，联邦学习(FL)被提出用于实现增强隐私的分布式机器学习方案，并已广泛应用于物联网(IoT)，医疗保健，计算机视觉和推荐等场景。标准的FL系统通常允许不同的参与者(即数据所有者)使用他们的本地数据单独训练ML模型，然后由中央服务器聚合以构建全局FL模型。然而，正如[^14]中所指出的，攻击者，例如恶意的中央服务器，只需要一小部分用户模型，就可以很容易地重建用户的数据，对图像具有像素级精度，对文本具有标记级匹配。为了减轻这种所谓的“梯度深度泄漏”，人们提出了隐私保护技术(PPT)，如同态加密(HE)、多方计算(MPC)、差分隐私(DP)，以及区块链和可信执行环境(TEE)等基础设施，通过以隐私保护的方式聚合用户的本地训练模型来增强FL系统。因此，隐私保护聚合(PPAgg)作为隐私保护联邦学习(PPFL)的关键协议。

一般来说，人们可以通过构建广泛应用于标准分布式隐私保护机器学习(PPML)的PPAgg协议来增强PPFL。然而，与PPML相比，PPFL进一步考虑了异构参与者，例如不同的计算能力和带宽，以及更复杂的隐私和安全威胁模型[20]。例如，在跨设备FL设置中，参与者通常是资源受限的移动设备，可能随时退出系统(详见第2节)。这就要求PPAgg协议同时提供经济有效的执行和退出弹性。同时，PPFL系统中的安全和隐私问题可能来自内部人员，例如FL参与者，或外部人员，例如模拟虚拟参与者，来自单个对手，例如中央服务器，或多个对手，例如几个串通参与者。此外，攻击者可以被认为是半诚实的，即试图在不偏离FL协议的情况下学习诚实参与者的私有信息;或者是主动恶意的，即试图通过任意偏离FL协议来学习其他诚实参与者的私有信息，例如通过操纵消息。因此，为了在不同的应用场景下实现PPFL，需要对PPAgg协议进行具体的设计。

目前，关于PPFL的研究很少从隐私保护聚合协议的角度来看待PPFL的构建和组织。本调查根据其用于保证隐私的主要工作进行分类。因为一个PPAgg协议可能涉及几种支持的隐私保护技术来提供不同的属性。例如，SecAgg[33]同时采用了屏蔽和秘密共享技术，在本次调查中被归类为基于屏蔽的聚合，因为使用了屏蔽技术来保护用户的模型隐私，而秘密共享主要提供了退出弹性。这些主要分类包括：(1) 基于HE的聚合； (2) 基于MPC的聚合； (3)基于DP的聚合； (4) 基于区块链的聚合以及(5)基于TEE的聚合。

## 2 联邦学习的概述和基础

### 2.1 联邦学习的概念

联邦学习方案通常允许不同的参与者(即数据所有者)使用他们的本地数据单独训练ML模型，然后通过中央服务器的协调将其聚合以构建全局FL模型。FL参与者可分为两类，即 (1) $n$个用户集合$U={u_1,u_2,...,u_n}$每个用户$u_i$都有一个本地数据集$D_i$还有 (2) 一个中央服务器$S$。
<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image49.png">
</div>
<center> Fig. 1. A typical workflow of the training process in FL systems.</center>

此外，如前所述，FL系统通常涉及数据格式、计算能力、带宽等方面的异构性。因此，为了在不同的环境下实现PPFL，需要对PPAgg协议进行具体的设计。这里我们保持了[^20]中FL设置分类的一致性，即$Cross-Silo$设置和$Cross-Device$设置，如表1所示。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/imag50.png">
</div>


### 2.2 联邦学习的隐私威胁
如前所述，FL系统中的隐私威胁可能导致不同的信息泄漏，并且来自内部人员(例如FL参与者)和外部人员(例如窃听者)。我们对FL中隐私威胁的讨论将主要集中在内部隐私泄漏上。我们应该注意到，在本调查中，我们关注的是PPAgg协议，该协议保护诚实FL参与者输入的隐私。旨在保证安全免受非隐私攻击(如后门攻击或中毒攻击[^34])的协议属于拜占庭鲁棒聚合[^35]，这超出了本文的讨论范围。我们将讨论它们与PPAgg协议的潜在集成，以进一步改进安全性。FL中的隐私威胁可以分为以下两种一般形式。
- 对用户模型的威胁：单个FL参与者的局部数据可以通过其局部训练模型的一小部分被泄露[14],这直接打破了标准联邦学习的基本隐私保障，因此，大量的PPAgg协议致力于处理这种隐私泄露。
- 对全局模型的威胁：标准的联邦学习方案假设全局模型是明文的。然而，在一些联邦学习应用场景中，要考虑全局模型的私密性。

此外，隐私泄露可能来自单个攻击者或多个攻击者，可以采取以下两种形式之一。
- 单个攻击者：一个单一、非串通的攻击者，可以是FL用户、服务器或第三方，中央服务器通常有更强的功能。
- 串通对手：串通可能发生在有或没有中央服务器的情况下。将FL用户与中央服务器和更多的对手串通起来通常会导致更大的隐私泄露风险。


考虑对手的能力，可以分为三种形式。
- 诚实：诚实的遵守协议。
- 半诚实(诚实但好奇)：试图在不偏离协议的情况下了解诚实参与者的私人信息。
- 主动恶意：可随时以任何方式偏离协议，例如操纵身份或向他人发送欺诈消息。

## 3 隐私保护聚合的技术
在本节中，概述了在FL系统中构建隐私保护聚合协议的支持工具，包括一些隐私保护技术，如一次性密码本(One-time Pad)，同态加密(homomorphic encryption)，安全多方计算(secure multi-party computation)，差分隐私(differential privacy)，以及区块链(blockchain)和可信执行环境(trusted execution environment)等基础设施。

### 3.1 One-time Pad
在密码学中，一次性密钥(OTP)是一种发送方随机生成只用于加密消息的一次的密钥的技术。在解密时，接收方需要使用匹配的OTP作为密钥。这样，OTP的随机性保证了每个消息的加密都是唯一的，与其他任何加密都没有关系，因此无法破解OTP加密的消息。
可以采用OTP以加法或乘法的形式对消息进行加密。例如，通过将随机生成的OTP随机数$r$添加到有限域$\mathbb{F}_p$中的消息$x$中，得到加密消息$y$，即$y=x+r \pmod p$。同样地，可以计算$y=x\cdot r \pmod p$，除非$r$被揭露，否则攻击者无法破解$y$。
基于OTP提供了完美的保密性，而DP仍然会泄露数据库的一些统计信息。而且基于otp掩码的聚合通常可以提供精确的结果，而基于dp的聚合不可避免地会受到噪声的影响，从而降低FL模型的性能。对于被otp加密的向量或模型，我们称之为掩码向量或掩码模型。

### 3.2 Homomorphic Encryption
同态加密是一种允许对加密数据执行函数求值，同时保留功能特征和数据格式的加密方案。作为具有密钥对$(pk,sk)$，两个消息$m_1$和$m_2$，可以使用$Enc(m_1,pk)$和$Enc(m_2,pk)$计算$Enc(m_1+m_2,pk)$；其中$Enc(\cdot)$为加密函数，$pk$为公钥，之后可以依靠相应的解密函数$Dec(\cdot)$和私钥$sk$获得$m_1$和$m_2$。根据允许对加密数据进行算术运算的次数进行分类。
- 部分同态加密(Partially Homomorphic Encryption)：只允许一种操作类型，例如加法和乘法，允许不限次数的操作。
- 有限同态加密(Somewhat Homomorphic Encryption)：允许某些类型的操作，但次数有限，例如一次乘法和无限次加法。
- 完全同态加密(Fully Homomorphic Encryption)：允许无限类型、无限次的算术运算。
对于FL系统中的隐私保护聚合，只涉及一种算术运算加法，因此PHE方案成为自然的选择。例如，Paillier加密系统[^39]在FL中被广泛采用，可以在加密数据上执行加法，从而保护用户隐私，ElGamal[^40]也可以通过将聚合转换为乘积来适应。为了保护整个FL工作中的隐私性，如全局模型，FL用户需要基于加密的全局模型来训练他们的局部模型，这需要对密文进行复杂的函数评估。因此，FHE被认为是唯一的选择，否则，必须将所有加密数据转换为秘密共享格式，并利用MPC协议来训练ML模型。在FHE方案中，基于格子的CKKS[^41]，[^42]是隐私保护FL中最常用的方案，因为它们在效率和准确性方面具有良好的权衡。PHE方案通常比SWHE方案更有效，而SWHE方案通常比FHE方案更有效。由于PPFL系统的隐私要求，SWHE在隐私保护聚合方面既优于PHE，在隐私保护训练方面也优于FHE。因此，SWHE通常被认为是支持其他高级加密协议的底层工具。例如，leveled BGV(一种SWHE)被用来构建通用MPC协议SPDZ[^43]。此外，我们应该注意到，通过牺牲一些效率，所有的HE方案都可以扩展到它们的阈值或多键版本，例如阈值Paillier[^44]和多键CKKS[^45]。在这种情况下，密钥分发给所有参与密钥生成过程的参与者。因此，与标准HE方案相比，必须破坏更多的FL参与者来破坏安全性，从而提高安全性。

### 3.3 安全多方计算
安全多方计算(MPC或SMPC)广泛涵盖了用于多方之间隐私保护功能评估的所有加密技术，包括但不限于同态加密(HE)，乱码电路(GC)，不经意传输(OT)和秘密共享方案(SSS)。它旨在允许多个参与方在不相互泄露私密输入的情况下进行计算，提供了一种保护个体数据隐私的方法，使得参与方可以共同进行计算并获得计算结果，而不必公开或共享原始数。MPC已经从纯粹的理论兴趣转向实际实现，并开发了许多通用框架来支持两方(例如ABY[^48])和多方设置(例如SPDZ家族[^49]和ABY3[^50])中的安全计算。此外，随着近年来机器学习的发展，一种支持隐私保护机器学习的高效MPC方案引起了学术界和工业界的极大关注，如[^48]、[^50]、[^51]。这些通用的PPML方案可以直接扩展以实现PPFL系统，其中用户将其本地数据或本地训练的模型共享给几个参与者，例如，在整个协议执行期间保持在线的非串通服务器。由于纯mpc在FL中的应用通常会导致不切实际的通信开销，特别是对于具有复杂ML模型的大型FL系统，因此通常考虑将简单的秘密共享方案与其他ppt集成，以实现FL中的隐私保护聚合或训练。
秘密共享是指允许秘密在一组参与者之间分发和重建的加密原语。正式地说，$a(t,n)$阈值秘密共享方案允许将一个秘密$s$分发给$N$个参与方$p_1,p_2,...,p_n$，只有数量不少于阈值$t$的各方中的任何一个子集才能重建秘密$s$，少于$t$的数量的参与方都不能获得关于秘密$s$的任何信息。加法秘密共享和Shamir秘密共享是构建此类MPC协议的两种广泛使用的方案。例如，在加性秘密共享方案中，秘密$s$在有限域$\mathbb{F}_p$被分成$n$个部分$s_1,s_2,...,s_n$使得$s=\sum_{i=1}^n  s_n mod p$。与加性秘密共享不同，Shamir秘密共享利用非线性映射来重建秘密，具体来说，对于$a(t,n)$Shamir方案，要共享一个秘密$s$，需要从有限域$\mathbb{F}_p$随机选择$t-1$个元素$a_1,a_2,...,a_{n-1}$，并且让$a_0=s$，构造多项式
$$f(x)=a_0+a_1+a_2x^2+\cdots+a_{t-1}x^{t-1} mod p$$
然后由拉格朗日多项式定义的曲线上$n$个不同的点将其作为股份分配给$n$方。为了重建秘密$s$，一旦收集到至少$t$个Shamir股份$(x_i,y_i)$，计算得到上述拉格朗日多项式的常数项
$$s=f(0)=\sum_{j=0}^{t-1}y_j \prod_{m=0,m\neq j}^{t-1}\frac{x_m}{x_m-x_j}$$
Shamir方案的阈值结构使得它可以很自然地用于处理丢失用户和构造验证协议。

### 3.4 差分隐私
差分隐私(DP)是一种解决从大数据集中学习知识但保护个体参与者隐私的悖论的技术。参考[^55]，DP的定义可以概括为：对于任意的两个相邻的数据库(NB)  $\chi$和$\chi'$，且对于所有可能的输出$s \subseteq R$，它满足$\epsilon-DP$当
$$\frac{P(M(\chi) \in S)}{P(M(\chi ' \in S))} \leq exp(\epsilon)$$
这里，$\epsilon$是隐私预算，控制$M$的两个输出和两个$NB$为输入的差异程度，$\epsilon$越小，参与者的隐私水平越高，但效用越低。当数据库满足以下两个条件之一时，数据库是$NB$的：(1)如果$\chi$和$\chi '$是两个数据库，且最多有一条记录不同；(2)如果$\chi$和$\chi '$有一个条目不同。
在FL中，通过特定选择的差分私有机制$M$，在数据中加入随机噪声或不同的模型参数，可以保护一对$NB \chi,\chi '$中的信息隐私，一些常用的噪声生成机制包括高斯机制和拉普拉斯机制。
对于中心/全局DP和局部DP的概念有不同的定义。由全局服务器或可信第三方服务器扰动参数的方法被视为基于GDP的工作，而本地用户添加噪声的技术被视为基于LDP的方法。差分隐私的本质保证了个体不可区分性，这使得所有基于dp的技术都具有防止成员推理攻击的能力。GDP也可以防止属性推理攻击，但如果没有大量的本地用户，将导致FL模型效用的巨大损失。FL在基于GDP的PPAgg方法在保证相同的隐私保护级别的情况下，比基于LDP的PPAgg方法增加的噪声更小，但它必须满足全局服务器可信或第三方可用的条件。基于LDP的PPAgg较为常见和实用，但这种方法不能有效地限制属性推理攻击。也有一些新的DP设置出现了实用的隐私损失计算方法，如$(\epsilon,\delta)-DP$，不同版本的集中差分隐私(CDP[^61],zCDP[^62],tCDP[^63])和Renyi差分隐私(RDP)[^64]，称之为标准DP定义的变体。


### 3.5 可信执行环境
可信执行环境(Trusted Execution Environment, TEE)，如GlobalPlatform所定义，是主处理器的一个安全区域，允许敏感数据和代码在一个隔离和可信的环境中进行存储、处理和保护[^67]。换句话说，TEE与纯软件环境隔离，即富操作系统执行环境(REE)。因此，TEE保证内部应用程序和相关数据的机密性和完整性，不受REE的任何攻击。
TEE的实现，例如[^68]，由硬件enclave支持，例如Intel SGX[^70]和ARM TrustZone[^71]，其中存在计算资源(例如有限的内存大小)和提供的安全级别之间的权衡。请注意，与基于ree的应用程序相比，TEE通常涉及硬件方面的额外成本，这可能会阻碍其大规模部署。

## 4 联邦学习中的隐私保护聚合协议
在本节中，调查了不同PPAgg协议的不同结构，在FL系统中的应用，分析了这些选定的PPAgg协议和解决方案的优缺点。
​	
### 4.1 基于掩码的聚合
**双向掩码屏蔽(Pair-wise masking)**，这个研究方向可以说是由SecAgg的设计开创的，作者提出了一种成对加性掩码技术，当FL用户的掩蔽模型聚合时，掩蔽可以自动取消。具体地说，假设有一组有序的FL用户$U$，每个用户$u_i \in U$都有一个向量$x_i$。在SecAgg协议中，每个用户可以向其持有的向量$x_i$添加一对相加掩码，以获得掩码向量$y_i$。
$$y_i=x_i+\sum_{i < j}PRG(s_{i,j})-\sum_{i>j}PRG(s_{j,i})$$
其中伪随机数生成器(PRG)可以根据种子$s_{i,j}$随机生成序列号。很明显当所有$y_i$通过以下方式相加掩码将会被抵消。
$$\sum_{u_i\in U}y_i=\sum_{u_i \in U}\Big(x_i +\sum_{i<j}PRG(s_{i,j})-\sum_{i>j}(PRG(s_{j,i})\Big)=\sum_{u_i \in U}x_i$$
此外，为了处理在协议执行期间被丢弃的FL用户，使用Shamir秘密共享方案在用户之间秘密共享种子。采Diffie-Hellman (DH)密钥交换协议对每对用户$(u_i,u_j)$。请注意，在种子和PRG的帮助下，种子协议的过程是必要的，每个FL用户只需要与其他人共享种子，而不是整个掩码向量，这大大减少了通信开销，特别是处理丢失的用户。为简单起见，这里我们省略了引入双重屏蔽、一致性检查和SecAgg中的其他技术来提高安全性。
但是SecAgg方案对于大规模的联邦学习应用程序来说是不划算的。对于一个$n$用户的FL系统，它需要$O(n^2)$个通信轮来运行对DH密钥交换协议。因此，从机器学习的角度引入了减少通信的技术，与SecAgg结合使用，以进一步降低开销。例如，在[^74]、中，设计良好的量化技术被用于优化通信效率。在[^76]中，作者将随机旋转技术与SecAgg相结合，积极调整用户模型的量化范围，以减小模型体积。CodedPaddedFL[^77]采用编码技术提高效率。[^78]中引入了异构量化，根据用户可用的通信资源来调整用户的量化水平。文献[^79]采用梯度稀疏化技术对用户模型进行压缩。此外，在[^80]中可以找到用于联邦子模型学习的基于secagg的PPAgg协议。然而，上述工作依赖于SecAgg方案进行聚合，因此在大规模FL系统中仍然涉及很高的通信开销。
为了减少SecAgg的通信开销，同时保持对屏蔽技术的使用，提出了一些通过优化拓扑结构来提升效率的方案，其中FL用户仅通过对用户子集进行通信而不是所有用户。例如，TurboAgg[^82]将$n$个FL用户划分为$n= \log n$个组，然后按照多组圆形结构进行聚合。在这种情况下，一个组中的每个FL用户只与下一个组中的用户通信。在SwiftAgg[83]中也可以找到类似的分组结构。然后，这些方案需要额外通信轮来处理组之间的通信，并牺牲一些安全保障来防止对手串通。   
因此，考虑具有非组体系结构的聚合方案。在CCESA[^84]中，作者证明了FL用户通信的方案，即在稀疏随机图而不是完整图上运行对DH密钥交换协议，提供了与SecAgg方案类似的安全保证，但通信开销更低。一个CCESA和SecAgg的拓扑结构对比如图2所示，CCESA[^84]通过Erdos-R¨enyi图实现稀疏随机图。在此图中，每一对FL用户都以概率p连接。因此，p的选择导致了安全级别和协议效率之间的权衡。在[^84]中给出了一个适当的p，提供了与SecAgg[^33]类似的安全保证，将通信复杂度从$O(n^2)$降低到$O(n \log  n)$。另一个独立的作品SecAgg+[^85]采用Harray图代替完全图进行对掩码的通信。与Erdos-R´enyi图不同，Harray图是一种k连通图，它的顶点具有尽可能少的边数。同样，在SecAgg+中选择合适的k也会导致$O(n log n)$的通信复杂度。

<div align="center" >
<img width=600px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-51.png">
</div>
另一个提升成对掩码的聚合方案效率的方向是用轻量级或非交互算法取代DH密钥交换协议。在Nike[^86]中，通过引入两个非串通的加密秘密提供者(辅助服务器)的帮助下，可以使用二元多项式以非交互方式生成每对FL用户的种子。在[^87]中提出的可适用于FL聚合的方案中，一个可信的经销商将种子分配给总和为零的用户。在FLASH[^88]中，在假设半诚实中心不与单个FL用户串通的情况下，作者提出一种轻量级同态加密算法，以双掩码屏蔽的方式，大大提升了效率。然而，Nike[^86]和FLASH[^88]的信任分布受到辅助服务器数量和非串通假设的限制，因此限制了一些应用场景。在SecAgg中使用Shamir的秘密共享方案，这样一组存活的用户可以重建被丢弃用户的种子来取消它们的掩码，秘密共享会导致退出弹性和更高的开销。最近的一项工作[^74]通过取消FL用户之间秘密共享种子的操作来提高SecAgg的效率，但当大量丢失用户的情况下通信成本较高。

**非成对掩码屏蔽(Non-pair-wise masking)**，双掩码技术涉及到FL用户对之间的种子协议交互，阻碍了大规模FL系统的有效部署。最近，一些工作用轻量级的非成对掩码，然后进行一次揭码。更具体地说，在有$n$个用户的方案中，每个FL用户$u_i$在不与其他用户交互的情况下生成自己的掩码$r_i$，使用它加密自己持有的向量$x_i(y_i=x_i+r_i)$上传到服务器。同时，所有用户都参与一个协议，允许中央服务器知道用户掩码的总和$R=\sum{r_i}$，保持每个$r_i$的隐私性，服务器通过计算$\sum_{x_i}=\sum_{y_i}-R$获得聚合结果。例如，在HyFed[^30]中，一个可信方参与计算来自用户的聚合噪声，然后将其发送到服务器进行一次性揭罩。在[^30]中，采用同态PRG (HPRG)实现了轻量级的掩码生成，从而大大降低了通信开销。此外，基于Shamir秘密共享方案和HPRG的乘性掩蔽和加性同态特性，服务器可以在不知道任何单个用户种子的情况下获得用于取消掩码的种子，从而取消掩码以获得正确的聚合结果。在[^72]中也采用了一次性解密的思想，其中一个受信任的第三方协调丢失的用户并协助计算解密。在后续的工作LightSecAgg[^91]中，作者提出了一种轻量级且具有dropout-resilience的秘密共享方法，从而在[^72]中删除了受信任的第三方，并允许服务器基于从活着的FL用户接收到的共享进行一次解密。其他一些方案通过链式结构实现一次揭罩[^95]，[^96]。具体地说，如图4所示，一个中央服务器或领导生成一个掩码，并将其分配给第一个用户$u_i$, $u_1$使用它来掩码它的模型。之后，$u_1$将自己的掩码模型传输给用户$u2$, u2将自己的模型加入到从$u_1$接收到的掩码模型中并传输给$u_3$。所有用户以链式方式一个接一个地聚合他们的模型，最后一个用户将其结果传输到中央服务器以解除屏蔽。然而，这些工作假设中央服务器是可信的，并且服务器和用户之间没有勾结，这对于现实生活中的FL应用程序是不实际的。
<div align="center" >
<img width=400px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-52.png">
</div>

### 4.2基于同态加密的聚合
FL中基于同态加密的聚合很直接。用户只需要加密它们的模型并将其发送到服务器，中央服务器根据使用的加性同态特性将接收到的加密模型加和在一起，再对其进行解密以获得该FL轮种的全局模型。
<div align="center" >
<img width=400px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-53.png">
</div>

FL种基于同态加密的聚合协议的安全性依赖于底层的加密系统安全。根据同态加密的特性，只有当密文使用相同的公钥加密，同态属性才成立。但是加密系统的密钥管理决定了威胁模型和应用场景，在用于FL聚合的加密系统中，工业部署时要考虑的重要因素是密钥的所有权。下面总结了密钥的所有权的情况。

- 1)：仅为所有FL用户所知，服务器不知；
- 2)：只为服务器所知，任何FL用户不知道；
- 3)：在所有或一组FL用户之间进行共享分割；


1)M1设置。在M1设置中，所有FL用户都知道密匙，但对中央服务器保密。在这种情况下，用户的模型隐私受到保护，但全局模型对所有FL参与者是公开的。密钥可以通过用户之间的交互或在可信第三方的帮助下生成。此外，密码系统可以通过不同的方式实例化以提供不同的安全级别，例如是否后量子，例如基于rsa的[116]，基于bgn的[117]，基于elgamal的[25]，基于paillier的[108]基于格的密码系统[122]。然而，上述方案需要严格的安全性假设，即所有用户至少是半诚实的，同时任何用户与中央服务器之间没有勾结。这个假设很弱，因为服务器可以通过创建一个假名的FL用户直接破坏用户模型隐私的安全性。

2)这种情况下密钥由中央服务器持有，目的是保护全局模型的隐私不受服务器的侵犯。这种考虑在许多FL应用中很常见，因为中央服务器通常是商业公司或咨询机构，它们打算使用FL来提高其ML模型性能，并将模型推理作为一种服务来提供商业利润。在这种情况下，全局模型的隐私被认为是受保护的。但是，由于中央服务器持有密钥，因此FL用户发送给服务器的加密模型可以被服务器解密，这直接破坏了用户模型隐私的安全性。因此，需要其他的隐私保护技术来进一步提高隐私保障。例如，在PrivFL[^101]中，只有服务器持有HE方案的秘密密钥，用户在聚合之前屏蔽他们的模型，并参与SecAgg协议来聚合掩码以解除掩码(参见图6)，因此保护了用户模型和全局模型的隐私。也有一些工作，依赖于可信方来管理密钥。在PIVODL[^130]中，每轮随机选择一个FL用户作为密钥生成器，从而增加随机性以提高安全性。然而，这些作品的信任分配仍然仅限于一方。此外，由于全局模型是加密的，FL用户必须在密态下训练他们的本地模型。可能导致不切实际的计算开销。
<div align="center" >
<img width=400px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-54.png">
</div>

3)在1中，所有用户或一组用户持有相同的密钥，因此，只要聚合服务器与拥有密钥的任何用户串通，密文就不再有意义。处理这种安全问题的一种直接方法是在一组用户之间拆分密钥。使用阈值加密系统，超过阈值数的几个用户必须合作才能解密加密消息。例如如图7所示，所有参与者按照以下工作方式实验隐私保护聚合。(i)用户参与密钥生成协议生成密钥对$(pk,sk)$，公钥$pk$为所有人所知，私钥$sk$为共享。每个用户$u_i$有一部分密钥$s_k^i$如$f(s_k^1,...,s_k^n)=s_k$。(ii)每个用户基于FL全局模型训练它的本地模型$w_i$，并使用公钥$pk$加密$Enc(w_i,pk)$发送给中央服务器。(iii)在收到加密的模型后。中央服务器依赖同态加密操作计算$Enc(w,pk)=\sum_{i=1}^nEnc(w_i,pk)=Enc(\sum_{i=1}^nw_i,pk)$，并将结果发送给用户。(iv)每个用户$u_i$使用它的部分密钥计算一个部分加密$p_i=Dec_p(s_k^i,Enc(w,pk))$并发送给服务器，(v)服务器计算$w=Dec(p_1,...p_n)$从而获得当前FL轮的全局模型聚合结果$w$，其中$Dec_p，Dec(\cdot)$有加密系统决定。
例如在[^135]中，引入了一种更有效的阈值Paillier加密系统的变体称为BCP。在基本阈值Paillier密码系统上，Helen[^136]集成了零知识证明和SPDZ的一些支持协议[^49]，以保证对主动恶意FL参与者的安全性。在聚合过程中，为了进一步提高全局FL模型而不仅仅是用户模型的隐私保证。需要对全局模型进行加密，此时用户必须在密文上训练它们的本地模型。因此支持任何算术运算的完全同态加密系统变得必要。采用基于格的FHE密码系统[^28]以实现更复杂的功能评估。并出于隐私目的扩展其多密钥版本。为了提高效率，其他一些工作[^142]采用了多输入功能加密方案，但是对于复杂的功能计算量较大，并且需要可信方进行密钥生成和分发，与基于阈值和多密钥加密系统的FL相比，安全性保障较弱。


### 4.3 基于安全多方计算的聚合
**共享模型**FL中的用户将本地训练模型分享到一组代理，例如，选定的用户或代理服务器，然后这些代理共同计算用户模型的和得到聚合结果的份额。之后，它们可能会选择重建结果，即新的全局FL模型。如在[^145]中，每个FL用户使用通用MPC协议将其本地训练的模型共享给所有用户进行聚合，在FastSecAgg[^147]中，通过牺牲一些安全性，作者将标准的Shamir秘密共享替换为更高效的基于FFT的多秘密共享方案。或者模型可以在两个、几个服务器之间进行共享，如[148]，[149]，[152]。其他一些研究引入了基于两阶段秘密共享的聚合[154][155]。在第一阶段所有用户都参与一个支持mpc的选择协议，以构建一个委员会。然后在第二阶段，所有用户将它们的模型共享给委员会中的用户进行聚合。此外，为了保证恶意中心服务器聚合结果的正确性，在[156]中采用了可验证的秘密共享方案。
**共享数据**，同样，如果FL用户将其本地数据分发到多个服务器上进行训练，而不是进行聚合，这种方案可以归于基于mpc的分布式ML训练。这种方案直接支持隐私保护聚合，因为本地训练的模型也在MPC参与者之间共享。这种隐私保护训练可以通过在两个[48]、三个[50]、四个或任意数量的服务器之间分别分配信任来实现，依赖于通用的MPC协议。例如采用ABY[^48]和SPDZ[^49]实现安全的联邦迁移学习。[160]部署了一种基于GMW协议的梯度树增强模型。在应用SPDZ协议的[136]中考虑了多方设置。这些工作是通用MPC协议在FL中的应用，其效率和安全性的提高主要来自其底层MPC方案。
只有当MPC参与者不串通或它们中的大多数是可信时，才能保证安全性。此外，大部分MPC隐私训练方案通常要求MPC参与者在整个MPC协议执行过程中保持在线状态，并具有足够的带宽和计算能力。因此不适用于移动设备或物联网设备，这些设备可能随时退出系统，在$cross-device$设置中很常见。



**处理掉线用户**，除了上述在MPC参与者之间直接共享模型或数据以保护隐私的工作外，还可以采用秘密共享方案作为支持协议来处理丢失的用户或验证FL系统中的计算结果。这些协议将获得dropout弹性，如在[30]，[33]中，使用Shamir方案共享生成掩码的种子，该方案允许中央服务器在在线用户大于阈值时重建被删除用户的掩码。提出的协议还允许对计算结果进行验证，如[153]只有当一组大于阈值的用户验证了聚合结果时，才承认对聚合结果的正确性。


### 4.4 基于差分隐私的聚合
与数据加密方法不同，基于dp的聚合是一种数据扰动方法，在FL中实现所需的计算开销较小。可以通过在FL训练参数中加入噪声来实现数据扰动。根据添加噪声的那一方(用户或服务器)可以分为LDP和GDP。
**LDP**，考虑到FL中的实际情况，假设没有可信服务器，大多采用LDP PPAgg协议保护本地用户的隐私，本地用户先扰动它们的本地模型再发送给服务器。在[163]中，利用高斯机制保证本地模型的$\epsilon$差分隐私，以实现车联网场景中安全准确的资源共享。SFSL[166]将LDP应用于子模型更新，以在电子商务推荐FL系统中实现对不同移动客户端的合理否认。在一个客户端-边缘云分层联邦学习系统中，基于ldp的带有高斯噪声的PPAgg协议被应用于裁剪客户端模型和边缘服务器。除了上述基于高斯噪声的LDP-FL模型外，还有一些研究工作用拉普拉斯噪声扰动局部模型中的非离散参数，以防止信息泄漏[168]。由于大多数基于ldp的PPAgg协议需要在每次迭代中对目标参数添加噪声进行FL训练，因此客户端总数、每次迭代中选择的客户端数量、迭代次数都会影响DP噪声的分配方法和添加量，从而影响模型的效用。[170]的研究也设计了通过考虑上述因素来调整或减少LDP噪声量的方法，以提高模型的可用性。
**GDP**，LDP一般情况下会增加更多的噪声，并且可能比基于GDP的隐私方法对模型效用造成更严重的损害。[176]中提出的方法通过高斯噪声的GDP技术扰动局部信息。他们还提供了一个K-client随机调度策略来选择用户进行FL模型训练。在Noisy-FL[177]中，利用隐私跟踪框架f-DP[58]精确跟踪隐私丢失，在全局模型上采用基于gdp的PPAgg协议，通过高斯机制解决需要大量客户端的限制。[178]中的作者在异构物联网环境中设计了个性化PPFL模型。他们通过在每次迭代过程中向全局模型中加入高斯噪声，获得具有$L_2$-灵敏度的$(\epsilon,\delta)-DP$的模型。他们假设退出的用户可以在不干扰正常训练过程的情况下重新加入模型训练。
**混合方法**，除了只使用LDP或GDP方法进行安全聚合外，也存在将其与其他PPAgg技术相结合的混合方法。[180]中分别将HE和DP加在高斯机制中，以防止FL中的局部梯度和共享模型的隐私泄露，即使在攻击者与多个参与者勾结的情况下，它们的方法也可以保护数据隐私。[182]中的工作使用MPC和DP使客户端信息不可区分，并保护FL中的全局模型更新，[183]中将LDP和功能加密相结合，以实现数据级和内容级的隐私保护。[190]将LDP与安全加密和zCDP结合起来，通过在每次训练迭代中添加更少的噪声来实现良好的效用-隐私权衡。因此，有必要考虑模型实用程序之间信息隐私的权衡问题。该模型的实用性包括但不限于收敛性能、通信效率和准确性。适当地将其他PPAgg技术与基于dp的安全方法相结合可以提高模型的实用性。

### 4.5基于可信执行环境的聚合
如图所示，FL中典型的基于TEE的聚合协议的工作流程：(i)所有用户加密它们本地训练的模型并将其发送到REE，(ii)TEE从REE装载接收加密的模型，(iii)然后解密和聚合它们，之后(iv)TEE输出聚合结果给REE，REE将聚合结果分发给所有用户。为了进一步增强对TEE潜在攻击的安全性，在将用户模型上传到TEE之前，采用DP技术对其进行扰动[208]。

<div align="center" >
<img width=400px  height=auto src="https://raw.githubusercontent.com/moon-Light404/read_paper_notes/master/note_image/image-55.png">
</div>

还有一些工作在TEE中部署ML训练算法[2]，[208]。
然而，由于TEE平台内存大小的限制，通常会导致TEE
的部分训练，或者在 较长时间延迟的情况下完全训
练。此外，签名和验证方案可以与TEE集成，以提供
诚实的本地培训[207]或正确聚合中央服务器的完整
性保证，基于TEE的PPAgg通常涉及到硬件方面的额外
成本，因此在FL中大规模部署TEE将是昂贵的。

## 5 联邦学习隐私保护框架
随着联邦学习的积极发展



## 6 未来方向和挑战
