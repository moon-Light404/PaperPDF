《LIGHTSECAGG: A LIGHTWEIGHT AND VERSATILE DESIGN FOR SECURE AGGREGATION IN FEDERATED LEARNING》一个轻量级的设计用于联邦学习中的安全聚合

最先进的安全聚合协议依赖于用户掩码使用的随机种子的秘密共享，从而能够重建和取消属于掉线(退出)用户的随机种子。然而，这种方法的复杂性随着用户数量的减少而大大增加。我们提出了一种名为LightSecAgg的新方法，通过将设计从“**丢失用户的随机种子重建”改为“通过掩码编码/解码对活跃用户进行一次聚合掩码重建**”来克服这一瓶颈。我们表明，LightSecAgg实现了与最先进的协议相同的隐私和退出弹性保证，同时显着降低了针对丢失用户的弹性开销。我们还证明，与现有方案不同，LightSecAgg可以应用于异步FL设置中的安全聚合。此外，我们提供了一个模块化的系统设计和优化的设备上并行化可扩展的实现，通过实现模型训练和设备上编码之间的计算重叠，以及提高并发接收和发送块掩码的速度。我们通过在具有大量用户的现实FL系统中对各种数据集(MNIST, FEMNIST, CIFAR-10, GLD-23K)上训练各种模型(逻辑回归，浅cnn, MobileNetV3和EfficientNet-B0)的广泛实验来评估LightSecAgg，并证明LightSecAgg显着减少了总训练时间。

掉线用户的两两种子重建---->幸存用户的一次聚合掩码重建

**Contributions**

LightSecAgg的主要思想是每个用户使用本地生成的随机掩码保护其本地模型。然后对这个掩码进行编码，并以这样一种方式共享给其他用户，即任何足够大的幸存用户集的聚合掩码都可以在服务器上直接重构。与之前的方案形成鲜明对比的是，**在这种方法中，服务器只需要在恢复阶段重建一个掩码，与丢失的用户数量无关**。

**Problem Seeting**

FL的安全聚合协议具有以下特性：

- 威胁模型和隐私保证(Privacy guatantee)。我们考虑一个威胁模型，其中用户和服务器是诚实的，但好奇。我们假设**多达T (out of N)可以相互串通**，也可以与服务器串通来推断其他用户的本地模型。安全聚合协议必须保证在聚合模型之外不能学到任何东西，即使多达T个用户相互合作也是如此。我们从很强的信息论意义上考虑隐私泄露。
- 掉线弹性(Drop-resiliency guarantee).在FL设置中，用户在协议执行过程中随时被丢弃或延迟是很常见的。我们假设在协议执行过程中最多有**D个被丢弃的用户**，即在潜在的丢弃后至少有N−D个幸存用户。该协议必须保证服务器能够正确地恢复幸存用户的聚合模型，即使多达D个用户丢失。
- 适用于异步FL

**Goal**

我们的目标是设计一种高效、可扩展的安全聚合协议，同时实现强大的隐私和退出弹性保证，并随用户数量N线性扩展，实现隐私保证$T=\frac{N}{2}$,退出弹性保证$D=\frac{N}{2}-1$，并且协议适用于同步和异步FL。

我们正式提出了LightSecAgg，它的思想是对本地生成的随机掩码进行编码，使服务器可以通过一次计算从编码的掩码中恢复掩码的集合，其成本不随N扩展。LightSecAgg有三个设计参数:(1)0≤T≤N−1表示隐私保证;(2) 0≤D≤N−1，表示退出弹性保障;(3) 1≤U≤N，表示目标存活用户数。其中，参数T、D、U的选择使N−D≥U > T≥0。

![image-20231029134944203](assets\综述论文总结\image-20231029134944203.png)



<img src="assets\综述论文总结\image-20231029135100618.png" alt="image-20231029135100618" style="zoom:50%;" />



<img src="F:\StudyNote\论文\综述论文总结.assets\image-20231029135122334.png" alt="image-20231029135122334" style="zoom:50%;" />

特点：每个用户随机选取掩码对本地模型进行掩码，但是要对掩码进行编码。每个用户发送一个编码掩码给另一个用户。每个用户将其掩码本地模型上传给服务器。每个幸存的用户将聚合的编码掩码发送到服务器，服务器重构幸存用户的聚合掩码来恢复模型的聚合。完成一次聚合掩码重建。




《Chain-AAFL: Chained Adversarial-Aware Federated Learning Framework》Chain-AAFL：链式对抗感知联合学习框架

**摘要**

但出于对隐私的考虑，只交换梯度。然而，模型中毒攻击和梯度深度泄漏的威胁仍然限制了它的实际应用。为了解决这些问题，我们提出了一种新颖的隐私保护 FL 框架（称为 Chain-AAFL），该框架基于链式多方计算范式和对抗感知梯度聚合方法。具体来说，链式通信机制可以在参与者之间传输屏蔽梯度。对抗感知梯度聚合可以避免模型中毒攻击造成的模型退化，并从所有客户端中逐步识别出对抗者。在 CIFAR-100 上的实验结果表明，我们提出的 Chain-AAFL 能够抵御模型中毒攻击，并在不影响训练模型的准确性和训练速度的情况下实现联合学习的隐私保护。

我们的 Chain-AAFL 算法主要利用了两种机制：1) Chained-Communication 机制可以在参与者之间传输屏蔽梯度；

1)  Adversarial-aware 梯度聚合可以避免模型中毒攻击造成的模型退化。而对抗感知协议则通过用户信心值将对抗者从所有普通参与者中区分和识别出来。在对抗感知协议中，我们设计了一种用户划分分组方法，以防止模型中毒攻击破坏模型，确保训练过程的稳定性。

<img src="https://media.springernature.com/full/springer-static/image/chp%3A10.1007%2F978-3-030-87571-8_21/MediaObjects/515511_1_En_21_Fig1_HTML.png?as=webp" alt="img" style="zoom:67%;" />

我们的 Chain-AAFL 采用对抗意识梯度聚合方法，以置信度为标志，在提高模型训练速度的同时识别参与者中的对抗者。我们的方案细节如图 1 所示。服务器的工作主要包括1）向参与者广播全局模型参数；2）创建置信度和随机数作为用户符号和掩码；3）通过置信度识别参与者是普通用户还是对手；4）根据置信度对参与者进行分组；5）聚合所有参与者的模型参数并更新全局模型。

<img src="assets\综述论文总结\image-20231029222409778.png" alt="image-20231029222409778" style="zoom:67%;" />



《COMMUNICATION-COMPUTATION EFFICIENT SECURE AGGREGATION FOR FEDERATED LEARNING》CCESA协议Erdos-R ˝ enyi 图

**摘要**

在本文中，我们提出了一种低复杂性的方案，相对于现有的安全解决方案，该方案使用大大减少的通信/计算资源来提供数据隐私。该方案的关键思想是将秘密共享节点的拓扑设计为稀疏随机图，而不是与现有解决方案对应的完全图。首先在图上得到了保证可靠性和保密性的充分必要条件。然后，我们建议特别使用Erdos-R " enyi图，并对所提议方案的可靠性/隐私性提供理论保证。通过广泛的现实世界实验，我们证明，我们的方案只使用传统方案所需资源的20 ~ 30%，在实际的联邦学习系统中保持了几乎相同的可靠性和数据隐私水平。

![image-20231029222603927](assets\综述论文总结\image-20231029222603927.png)

- 在$G(n,p)$模型中，通过随机连接$n$个独立节点构造一个图，每条边出现的概率是$p$，且不同边存在与否相互独立，对于具有$n$个顶点和$M$条边的图，其出现的概率是$p^M(1-p)^{C^2_n-M}$。由此$p$越大，G中出现边较多的图的概率会上升。









---

《Partially Encrypted Multi-Party Computation for Federated Learning》2021 IEEE

摘要 ：

我们提出对模型的关键部分(梯度)参数进行加密，以降低通信成本，同时保持MPC在隐私保护方面的优势，而不牺牲学习到的联合模型的准确性。理论分析和实验结果验证了该方法可以通过重构个体参与者的原始数据来防止梯度攻击造成的深度泄漏。在MNIST和CIFAR-10数据集上使用深度学习模型的实验表明，与传统的MPC方法相比，我们提出的部分加密MPC方法可以显著降低通信和计算成本，并且与传统的使用明文聚合本地模型的分布式学习方法一样具有较高的准确性。

<img src="assets\综述论文总结\image-20231031210905825.png" alt="image-20231031210905825" style="zoom: 67%;" />

由于存在梯度泄露攻击，第一个隐藏层的梯度是基于输入数据$X_i$计算得到的，还有从第二隐藏层反向传播的结果。因此我们加密第一个隐藏层作为梯度$Type A$来阻止训练数据的重建。文中通过实验也得验证了仅对第一隐藏层进行加密就足以抵御DLG和iDLG的攻击。

<img src="assets\综述论文总结\image-20231031211206488.png" alt="image-20231031211206488" style="zoom: 67%;" />

安全多方计算MPC聚合$Type $ A梯度$g_1^A,g_2^A,g_3^A,...g_m^A$，在Step2中，每个参与者的Type A矩阵梯度被分割为m-1个共享秘密，$D_{i1}^A,D_{i2}^A,....D_{i(i-1)}^A,D_{i(i+1)}^A,...D_{im}^A$，采用加性秘密共享MPC协议。Step3中$P_j$接收到$\{D_{ij}^A\}^m_{i=1,i \neq j}$，

计算模型聚合的初始结果为$D_j^A=\sum_{i=1,i \neq j}^m D_{ij}^A$, 并代替为$g_j^A$。

<img src="assets\综述论文总结\image-20231031211236928.png" alt="image-20231031211236928" style="zoom:67%;" />





《FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated Learning》

在本文中，我们提出了一种安全的聚合协议FastSecAgg，它在计算和通信方面都是高效的，并且对客户端退出具有鲁棒性。FastSecAgg的主要组成部分是一种基于快速傅里叶变换(FFT)的新型多秘密共享方案FastShare，这可能是独立的兴趣。FastShare在理论上是信息安全的，并在秘密数量、隐私阈值和退出容忍度之间实现了平衡。利用FastShare的功能，我们证明FastSecAgg是(i)安全的，防止服务器与某些常数分数的任何子集(例如;~ 10%)诚实但好奇的客户;并且(ii)容忍某些常数分数的随机子集(例如;约10%)的客户。FastSecAgg在实现相同(有序)通信成本的同时，实现了比现有方案明显更小的计算成本。此外，它保证了对自适应对手的安全性，这些对手可以在协议执行期间动态地执行客户端破坏。

![image-20231102153311603](assets\综述论文总结\image-20231102153311603.png)

----

《VerifyNet: Secure and Verifiable Federated Learning》

《VERSA: Verifiable Secure Aggregation for Cross-Device Federated Learning》

