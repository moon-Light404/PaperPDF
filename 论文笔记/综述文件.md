# Privacy-Preserving Aggregation in Federated Learning: A Survey(联邦学习隐私保护聚合:文献综述)

## 保护隐私的聚合技术

SecAgg[^33]技术同时采用了屏蔽和秘密共享技术，在本次调查中被归类为基于屏蔽的聚合，因为使用了屏蔽技术来保护用户的模型隐私，而秘密共享主要提供了退出弹性。

这些主要分类包括(i)基于掩码的聚合，(ii)基于he的聚合，(iii)基于mpc的聚合，(iv)基于dp的聚合，(v)基于区块链的聚合，以及(vi)基于tee的聚合。

### **同态加密**

对于FL系统中的隐私保护聚合，由于它只涉及一种算术运算，即加法，因此PHE方案成为自然的选择。例如，Paillier加密系统[^39]在FL中被广泛采用，可以对加密的数据进行添加，从而保护用户的隐私。ElGamal加密系统[^40]也可以通过将聚合转换为产品来适应。此外，为了保护整个FL工作流的隐私性，例如全局模型，FL用户需要基于加密的全局模型来训练他们的局部模型，这需要对密文进行复杂的函数评估。因此，FHE方案是被认为是唯一的选择。否则，必须将所有加密数据转换为秘密共享格式，并利用MPC协议来训练ML模型。在FHE方案中，基于格子的CKKS[^41]，[^42]方案由于其在效率和准确性方面的良好权衡，是最常用的用于隐私保护FL的方案。请注意，PHE方案通常比SWHE方案更有效，而SWHE方案通常比FHE方案更有效。由于PPFL系统的隐私要求，SWHE在隐私保护聚合方面既优于PHE，在隐私保护训练方面也优于FHE。因此，SWHE通常被认为是支持其他高级加密协议的底层工具。例如，leveled BGV(一种SWHE)被用来构造通用MPC协议SPDZ[^43]。此外，我们应该注意到，通过牺牲一些效率，所有的HE方案都可以扩展到它们的阈值或多键版本，例如阈值Paillier[^44]和多键CKKS[^45]。在这种情况下，密钥分发给所有参与密钥生成过程的参与者。因此，与标准HE方案相比，必须破坏更多的FL参与者来破坏安全性，从而提高安全性。	

### **安全多方计算**

自[^16]的一般定义以来，MPC已经从纯粹的理论兴趣转向实际实现[^46]，[^47]，并开发了许多通用框架来支持两方(例如ABY[^48])和多方设置(例如SPDZ家族[^49]和ABY3[^50])中的安全计算。此外，随着近年来机器学习的发展，一种支持隐私保护机器学习的高效MPC方案引起了学术界和工业界的极大关注，如[^48]、[^50]、[^51]、[^52]、[^53]、[^54]。请注意，这些通用的PPML方案可以直接扩展以实现PPFL系统，其中用户将其本地数据或本地训练的模型共享给几个参与者，例如，在整个协议执行期间保持在线的非串通服务器(参见章节4.3)。由于纯mpc在FL中的应用通常会导致不切实际的通信开销，特别是对于具有复杂ML模型的大型FL系统，因此通常考虑将简单的秘密共享方案与其他ppt集成，以实现FL中的隐私保护聚合或训练。

### **区块链**

为了实现更复杂的功能评估，例如，超过区块链的聚合，而不仅仅是数据记录，使用智能合约[^65]，它可以写入代码行，并在满足预定义条件时自动执行。一般来说，智能合约一旦部署在区块链中就无法修改，并且它的执行也是去中心化的，保证了控制功能的稳定可靠[^66]。

### **TEE**

可信执行环境(Trusted Execution Environment, TEE)，如GlobalPlatform所定义，是主处理器的一个安全区域，允许敏感数据和代码在一个隔离和可信的环境中进行存储、处理和保护。换句话说，TEE与纯软件环境隔离，即富操作系统执行环境(REE)。因此，TEE保证内部应用程序和相关数据的机密性和完整性，不受REE的任何攻击。



## **隐私保护聚合协议**

## Masking-based Aggregation

#### **<mark>Pair-wise masking</mark>**

如3.1节所述，可以采用基于otp的屏蔽技术对消息进行加密，以充分保护其隐私。例如，在典型的联邦学习系统中，用户可以屏蔽他们的模型，然后将它们上传到中央服务器进行聚合。这需要设计良好的协议，以使中央服务器能够从这些屏蔽模型中获得聚合结果。这个研究方向可以说是由SecAgg的设计开创的，作者提出了一种成对加性掩蔽技术，当FL用户的掩蔽模型聚合时，掩蔽可以自动取消。

为简单起见，这里我们省略了在SecAgg中引入的双重屏蔽、一致性检查和其他提高安全性的技术，我们建议感兴趣的读者参阅[^33]了解详细信息。

注意，SecAgg方案对于大规模的联邦学习应用程序来说是不划算的。对于一个$n$用户的FL系统，它需要$O(n^2)$个通信轮来运行对$DH$密钥交换协议。因此，从机器学习的角度引入了减少通信的技术，与SecAgg结合使用，以进一步降低开销。例如，在[^74]、[^75]中，设计良好的量化技术被用于优化通信效率。在[^76]中，作者将随机旋转技术与$SecAgg$相结合，积极调整用户模型的量化范围，以减小模型体积。CodedPaddedFL[^77]采用编码技术提高效率。[^78]中引入了异构量化，根据用户可用的通信资源来调整用户的量化水平。文献[^79]采用梯度稀疏化技术对用户模型进行压缩。此外，在[^80]和[^81]中可以找到用于联邦子模型学习的基于secAgg的PPAgg协议。然而，上述工作依赖于SecAgg方案进行聚合，因此在大规模FL系统中仍然涉及很高的通信开销。

为了减少SecAgg的通信开销，同时保持对双掩码屏蔽技术的使用，提出了几个后续方案，其中FL用户仅跨用户的子集而不是所有用户进行通信。例如，TurboAgg[^82]将n个FL用户划分为$n/logn$个组，然后按照多组圆形结构进行聚合。在这种情况下，一个组中的每个FL用户只与下一个组中的用户通信。在SwiftAgg[^83]中也可以找到类似的分组结构。然而，这些方案需要额外的通信轮来处理组之间的通信，并牺牲一些安全保证来防止对手串通。

因此，考虑具有非组体系结构的聚合方案。在CCESA[^84]中，作者证明了FL用户通信的方案，即在稀疏随机图而不是完整图上运行对DH密钥交换协议，提供了与SecAgg方案类似的安全保证，但通信开销更低。CCESA and SecAgg说明性拓扑如图所示。CCESA[^84]通过Erdos-R¨enyi图实现稀疏随机图。

在此图中，每一对FL用户都以$概率p$连接。因此，p的选择导致了安全级别和协议效率之间的权衡。在[^84]中给出了一个适当的p，提供了与SecAgg[^33]类似的安全保证，将通信复杂度从$O(n^2)$降低到$O(n log n)$。

![2](assets\综述文件\image-20231022123417637.png)

另一个独立的作品SecAgg+[^85]采用$Harray$图代替完全图进行对掩码的通信。与$Erdos-R´enyi$图不同，$Harray$图是一种$k连通图$$，它的顶点具有尽可能少的边数。同样，在SecAgg+中选择合适的k也会导致$$O(n log n)$的通信复杂度。

另一个提高基于成对掩码的聚合方案效率的方向是<u>用轻量级或非交互算法</u>取代DH密钥交换协议。例如，在Nike[^86]中，在两个非串通的加密秘密提供者(即辅助服务器)的帮助下，可以使用二元多项式以非交互方式生成每对FL用户的种子。在[^87]中提出的可适用于FL聚合的方案中，涉及一个可信的经销商将总和为零的种子分配给用户。在FLASHE[^88]中，在假设半诚实中心不与任何单个FL用户串通的情况下，作者提出了一种轻量级同态加密算法，采用对屏蔽方式，大大提高了效率。然而，Nike[^86]和flash[^88]的信任分布受到辅助服务器数量和非串通假设的限制，因此限制了它们的应用场景。注意，为了处理被丢弃的用户，即取消他们的掩码，所有用户的种子被秘密共享，例如，在SecAgg中使用Shamir的秘密共享方案，这样一组活着的用户可以重建被丢弃用户的种子来取消他们的掩码。

因此，秘密共享会导致退出弹性和更高的开销。或者，最近的一项工作[^74]通过**取消FL用户之间秘密共享种子的操作来提高SecAgg的效率**，如果没有丢失用户，则通信成本要低得多，但涉及大量丢失用户的情况下通信成本较高。与[^74]类似，[^89]的作者删除了种子秘密共享操作，但要求所有存活的FL用户上传整个掩蔽向量的共享以处理丢弃的用户。

除了在单个FL回合中保护用户隐私之外，还有一些研究关注通过多轮FL训练所引起的隐私问题，例如，FedBuff[^90]和LightSecAgg	[^91]允许异步聚合，其安全性可以通过集成现有的PPAgg协议来增强。在最近的一项工作[^92]中，作者指出，即使使用上述隐私保护聚合协议，由于用户的动态参与，多轮FL训练也可能导致严重的信息泄露。如图3所示，用户$u1,u2,u3$参与轮t，用户$u1,u2$参加第t + 1轮。如果$u_1$和$u_2$的模型在两轮中没有明显的变化，服务器可以以很小的误差重建u3的模型。应该注意这个隐私问题，因为当全局FL模型收敛时，它在FL训练中很常见。在[^92]中，提出了一种朴素的缓解方法，该方法需要从一组用户批次而不是单个用户中进行聚合，因此攻击者无法长时间区分同一批次中的用户模型。

![image-20231022153035421](assets\综述文件\image-20231022153035421.png )



#### <mark>Non-pair-wise masking</mark>

尽管对掩码技术提供了在聚合所有掩码向量时可以取消掩码的诱人特性，但它自然涉及到FL用户对之间的种子协议交互，从而阻碍了大规模FL系统的有效部署。因此，最近的一些作品用轻量级的非成对掩码代替成对掩码，然后进行一次解码(unmasking)。

更具体地说，在有n个用户的方案中，每个FL用户$u_i$在不与其他用户交互的情况下生成自己的掩码$r_i$，并使用它来加密自己持有的向量$x$，然后以加性掩码的方式将掩码向量(例如$y_i = x_i + r_i$)上传到中央服务器。同时，所有用户都涉及一个协议，该协议允许中央服务器知道用户掩码的总和$R=\sum r_i$，同时保持每个$r_i$的隐私性。

在这种情况下，服务器可以通过计算$\sum x_i=\sum y_i-R$来获得聚合结果。例如，在HyFed[^93]中，一个可信方参与计算来自用户的聚合噪声，然后将其发送到服务器进行一次性揭罩。在[^30]中，采用同态PRG (HPRG)实现了轻量级掩码生成，从而大大降低了通信开销。此外，基于Shamir秘密共享方案和HPRG的乘性掩蔽和加性同态特性，服务器可以在不知道任何单个用户种子的情况下获得用于取消掩码的种子，从而取消掩码以获得正确的聚合结果。

类似基于HPRG的方案在[^94]中提出。在[^72]中也采用了一次性解密的思想，其中一个受信任的第三方协调丢失的用户并协助计算解密。在后续的工作LightSecAgg[^91]中，作者提出了一种轻量级且具有$dropout-resilience$的秘密共享方法，从而在[^72]中删除了受信任的第三方，并允许服务器基于从活着的FL用户接收到的共享进行一次解密。其他一些方案通过<mark>链式结构</mark>实现一次揭罩[^95]，[^96]，[^97]，[^98]。具体地说，如图4所示，假设所有FL用户$u_i$上的总订单，一个中央服务器或领导生成一个掩码，并将其分配给第一个用户$u_1$,$u_1$使用它来掩码它的模型。之后，$u_1$将自己的掩码模型传输给用户$u_2$, $u_2$将自己的模型加入到从$u_1$接收到的掩码模型中并将它传输给$u_3$。按照这种方式，所有用户以链式方式一个接一个地聚合他们的模型，最后一个用户将其结果传输到中央服务器以解除屏蔽。<u>然而，这些工作假设中央服务器是可信的，并且服务器和用户之间没有勾结，这对于现实生活中的FL应用程序是不实际的。</u>

![image-20231022154900527](assets\综述文件\image-20231022154900527.png)



#### <mark>Protecting the global model</mark>

上述基于掩码的聚合协议旨在保护FL用户模型或梯度的隐私，从而保护他们的原始数据。然而，为了保护全局FL模型的隐私，需要集成额外的隐私保护技术。在[^100]中，服务器屏蔽了全局模型，并要求所有FL用户基于屏蔽模型进行训练。训练结束后，每个用户向服务器发送一些补充信息，以便揭开掩码。请注意，与标准FL方案相比，这种方案没有在用户模型上提供额外的隐私保护。在PrivFL[^101]中，采用了**两方计算技术**，允许每个服务器-用户对共同训练一个ML模型，同时保持全局模型和用户局部模型的隐私性。之后，每个用户屏蔽其共享并将其发送到服务器，所有用户都参与到隐私保护协议中，例如SecAgg[^33]或SecAgg+[^85]，来聚合它们的掩码的总和，然后由服务器使用这些掩码来解除掩码。**此外，还考虑了其他一些集成技术，以提高整个聚合过程中的安全性**。例如，在[^102]中，在用户模型中加入差分私有噪声，以保证聚合加权平均时的隐私性。采用[^74]中的TEE、[^103]中的伪随机函数、[^104]中的类mac技术、[^106]中的同态哈希、[^107]中的零知识证明和[^105]中的承诺方案来保证服务器正确地聚合来自FL用户的总和。

到目前为止，我们已经回顾了基于掩码的聚合协议，以保护用户模型隐私和全局模型隐私。我们应该注意到，基于成对屏蔽的聚合协议允许对丢弃的用户进行有效的解除屏蔽，因此适用于跨设备(cross-device)设置，其中FL用户是随时可能退出系统的移动物联网设备。相比之下，基于一次性去掩码的聚合协议通常在跨组织(cross-silo)设置方面效率更高。在大多数情况下，在安全性假设(例如，可信方或非串通参与者)和效率(例如，计算、通信或存储成本)之间存在权衡。此外，为了提供除隐私角度之外的额外安全性，需要考虑其他加密工具和可信环境。综上所述，我们在表2中列出了上述具有相关特性的聚合方案。



## HE-based Aggregation

一般来说，要在FL轮中汇总用户的本地训练模型的总和，用户只需要加密他们的模型并将其发送到中央服务器。然后，中央服务器根据使用的加密系统的加性同态特性将接收到的加密模型添加在一起，可以对其进行解密以获得该FL轮中的全局模型(参见图5)。FL中基于he的聚合协议的安全性是通过底层的加密系统来实现的，只有当密文使用相同的公钥加密时，同态属性才成立。因此，在像FL这样的分布式环境中，**加密系统的密钥管理通常决定了威胁模型和应用场景**。更具体地说，对于用于FL聚合的公钥加密系统，在工业部署时要考虑的最重要因素是密钥的所有权。

![image-20231022162813500](assets\综述文件\image-20231022162813500.png)

M1 setting.在M1设置中，所有FL用户都知道密匙，但对中央服务器保密。在这种情况下，用户的模型隐私受到保护，但全局模型对所有FL参与者是公开的。密钥可以通过用户之间的交互[^108]，[^109]，[^110]或在可信第三方的帮助下[^111]，[^112]，[^113]，[^114]，[^115]生成。此外，密码系统可以通过不同的方式实例化以提供不同的安全级别，例如是否后量子，例如基于rsa的[^116]，基于bgn的[^117]，基于elgamal的[^25]，基于paillier的[^108]，[^109]，[^112]，[^114]，[^118]，[^119]，[^120]，[^120]，[^121]，基于格的密码系统[^122]，[^123]。然而，上述方案需要严格的安全性假设，即所有用户至少是半诚实的，同时任何用户与中央服务器之间没有勾结。这个假设很弱，因为服务器可以通过创建一个假名的FL用户直接破坏用户模型隐私的安全性

M2 setting.在M2设置中，密钥由中央服务器持有，目的是保护全局模型的隐私不受服务器的侵犯。这种考虑在许多FL应用中很常见，因为中央服务器通常是商业公司或咨询机构，它们打算使用FL来提高其ML模型性能，并将模型推理作为一种服务提供给商业利润。在这种情况下，全局模型的隐私被认为是受保护的。因此，需要其他的隐私保护技术来进一步提高隐私保障。例如，在PrivFL[^101]中，只有服务器持有HE方案的秘密密钥，用户在聚合之前屏蔽他们的模型，并参与SecAgg协议来聚合掩码以解除掩码。其他工作，如[^111]，[^116]，[^125]，[^126]，[^127]，[^128]，[^129]依赖于可信方来管理密钥。在PIVODL[^130]中，每轮随机选择一个FL用户作为密钥生成器，从而增加随机性以提高安全性。然而，这些作品的信任分配仍然仅限于一方。此外，由于全局模型是加密的，FL用户必须在密态下训练他们的本地模型，因此涉及FHE或MPC，这可能导致不切实际的计算或通信开销，特别是在跨设备设置中。

M3 setting.所有用户或一组用户持有相同的秘钥，因此，只要聚合服务器与拥有秘钥的任何用户串通，密文就不再有意义。处理此安全问题的一种直接方法是在一组用户之间拆分密钥，即M3设置。在这种情况下，使用阈值加密系统，**超过阈值数的几个用户必须合作才能解密加密消息**。这种设置在M1设置的基础上提高了安全保障，因为中央服务器必须与更多的FL用户串通才能破坏安全性。如图7所示，

(i)所有参与者按照以下方式工作实现保护隐私的聚合。用户参与密钥生成协议以生成密钥对$(pk;sk)$公钥$pk$为所有人所知，秘钥$sk$为各参与方共享。每个用户$u_i$都有一个部分秘密密钥，使得$f(s_1^k;...;s_k^n = s_k$，其中f(·)根据所使用的密码系统确定。(ii)每个用户基于全局FL模型训练自己的局部模型$w_i$，使用公钥$p_k$对其进行加密，发送$Enc(w_i;p_k)$到中央服务器。(iii)中央服务器收到用户的加密模型后，计算$Enc(w,p_k) =\sum_{i=1}^nEnc(w_i,p_k) = Enc(\sum_{i=1}^nwi,p_k)$依赖同态运算，并将结果发送给用户。(iv)每个用户$u_i$使用其部分秘密密钥计算部分解密$p_i=Dec_p(s^i_k,Enc(w,p_k))$并将其发送到服务器，服务器根据使用的加密系统确定$Dec_p$。(v)服务器收到用户的部分解密后，计算$w = Dec(p_1;...;p_n)$，得到聚合结果w，即当前FL轮的全局模型，其中Dec(·)根据所使用的加密系统确定。

![image-20231022165909198](assets\综述文件\image-20231022165909198.png)

例如，[^131]、[^132]、[^133]、[^134]采用了阈值Paillier密码系统。在[^135]中，引入了一种更有效的阈值Paillier加密系统的变体，称为BCP。在基本阈值Paillier密码系统上，Helen[^136]集成了零知识证明和SPDZ[^49]的一些支持协议，以保证对主动恶意FL参与者的安全性。为了改进计算和效率，在[^137]中部署了基于elgamal的加密系统。[^138]中提出了一种用于FL中聚合的轻量级AHE方案。然而，上述部分HE方案只支持加法或乘法。因此，它们只适合用于只涉及加法运算的聚合部分，而不适合用于涉及复杂算术运算的函数。



##  MPC-based Aggregation

**Share model**.  对于分布式机器学习和联邦学习等多方设置，MPC可以成为增强系统安全保障的自然选择。许多工作采用MPC方法来实现隐私保护聚合和进一步联邦学习隐私保护训练。基于mpc的隐私保护聚合协议允许FL用户分发，即共享(见3.3节)，他们的本地训练模型给一组代理，例如，选定的用户或助理服务器。然后这些代理共同计算用户模型的和，得到聚合结果的份额。之后，他们可能会选择重建结果，即新的全局FL模型。例如，在[^145]，[^146]中，每个FL用户使用通用MPC协议将其本地训练的模型共享给所有用户进行聚合。在Fastsecagg[^147]中，通过牺牲一些安全性，作者将标准的Shamir秘密共享替换为更高效的基于fft的多秘密共享方案。或者，模型可以在两个服务器之间共享，如[^148]，[^149]，[^150]，[^151]，或者几个服务器之间共享，如[^152]，[^153]。其他一些研究引入了基于两阶段秘密共享的聚合[^154]，[^155]。在第一阶段，所有用户都参与一个支持mpc的选择协议，以构建一个委员会。然后在第二阶段，所有用户将他们的模型共享给委员会中的用户进行聚合，依赖于类似于上述工作的标准MPC协议。

**Share data**.

同样，如果FL用户将其本地数据分发到多个服务器上进行训练，而不是进行聚合，如图8(b)所示，则该方案可以归结为基于mpc的分布式ML训练。请注意，这种方案直接支持隐私保护聚合，因为本地训练的模型也在MPC参与者(即服务器或选定的用户)之间共享。一般来说，这种隐私保护训练可以通过在两个[^48]、[^51]、三个[^50]、[^52]、四个[^53]、[^54]或任意数量的服务器之间分别分配信任来实现，这些服务器依赖于通用的MPC协议。例如，[^157]采用ABY[^48]和SPDZ[^49]实现安全的联邦迁移学习。[^158]和[^159]依赖于2PC协议。[^160]部署了一种基于GMW协议的梯度树增强模型。在应用SPDZ协议的[^136]，[^161]中考虑了多方设置。请注意，这些工作是通用MPC协议在FL中的应用，其效率和安全性的提高主要来自其底层MPC方案。我们建议有兴趣的读者参阅[^162]了解最先进的MPC协议的详细信息。

​	然而，MPC的特性限制了它的应用范围。首先，在所有用户之间共享秘密通常会导致很大的通信开销。因此，对于一个实用的纯MPC系统，FL用户的数据或模型必须传输给少数MPC参与者。在这种情况下，只有当MPC参与者不串通或他们中的大多数是可信的时，才能保证安全性。此外，上述基于MPC的隐私保护训练方案通常要求所有MPC参与者在整个MPC协议执行过程中保持在线状态，并具有足够的带宽和计算能力。因此，这些MPC参与者不能是资源受限的移动设备或物联网设备，**这些设备可能随时退出系统，这在跨设备FL设置中很常见**。

**Handle dropped users**.

除了上述在MPC参与者之间直接共享模型或数据以保护隐私的工作外，还可以采用秘密共享方案作为支持协议来处理丢失的用户或验证FL系统中的计算结果。如3.3节所述，一个阈值秘密共享方案，例如Shamir秘密共享，可以是一个自然的选择，即使一组用户的数量大于阈值，也可以使协议执行。

如果将这些用户设置为在线用户，则提出的协议将获得dropout弹性。例如，在[^30]，[^33]，[^84]，[^85]中，使用Shamir方案共享生成掩码的种子，该方案允许中央服务器在在线用户数大于阈值时重建被删除用户的掩码。如果将这些用户设置为诚实用户，则提出的协议将允许对计算结果进行验证。例如，[^153]、[^156]只有当一组大于阈值的用户验证了聚合结果时，才承认对聚合结果的正确性进行验证。

然而，我们应该注意到，阈值的设置会导致根据其使用情况进行权衡。阈值越大，安全保障越强，协议效率越低，反之亦然。



## DP-based Aggregation

与数据加密方法不同，基于dp的聚合是一种数据摄动方法，在FL中实现PPAgg所需的计算开销较小。根据不同的统计数据分布机制，可以通过在FL训练参数中加入噪声来实现数据摄动。如3.4中所介绍的，根据谁(可信的策展人/服务器或数据所有者)操作数据扰动过程，DP在FL中可以分为GDP和LDP。GPD协议和LDP PPAgg协议都有各自的优点和局限性。在本小节中，我们将回顾利用基于dp的技术来保护FL信息隐私的相关研究工作。

**LDP.** 

考虑到FL中的实际情况，<u>假设没有可信服务器可用更为合理</u>。因此，以往的研究大多采用LDP PPAgg协议来保护本地用户的隐私。本地用户在将本地更新发送到全局服务器之前扰乱了他们的信息。在[^163]中，作者利用高斯机制保证对局部模型的$\epsilon-$差分隐私，以实现车联网(Internet of Vehicles, IoV)场景中安全准确的资源共享。另一项研究[164]也考虑了车联网中的隐私保护问题。作者将他们提出的新颖LDP模型与FedSGD算法[^165]相结合，对上传的局部梯度进行扰动，以保护车辆用户的隐私信息。他们所提出的LDP-FedSGD模型能够约束隶属度推理的成功，并且比三种对比的模型具有更好的精度性能。

SFSL[^166]将LDP应用于子模型更新，以在电子商务推荐FL系统中实现对不同移动客户端的合理否认。在一个客户端-边缘云分层联邦学习系统中，基于ldp的带有高斯噪声的PPAgg协议被应用于裁剪客户端模型和边缘服务器。除了上述基于高斯噪声的LDP-FL模型外，还有一些研究工作用拉普拉斯噪声扰动局部模型中的非离散参数，以防止信息泄漏[^168]，[^169]。由于大多数基于ldp的PPAgg协议需要在每次迭代中对目标参数添加噪声进行FL训练，因此客户端总数、每次迭代中选择的客户端数量、迭代次数都会影响DP噪声的分配方法和添加量，从而影响模型的效用。[^170]、[^171]、[^172]、[^173]的研究也设计了通过考虑上述因素来调整或减少LDP噪声量的方法，以提高模型的可用性。

**GDP.**

尽管LDP可以保护FL中个人用户的隐私，并且可以满足没有可信的管理员/服务器可用的情况，但它增加了更多的噪声，并且可能比基于gdp的隐私增强方法对模型效用造成更严重的损害。因此，也有一些工作尝试使用GDP方法来实现FL中的PPAgg。第一个从用户层面考虑FL优化中的GDP的作品是[^174]。作者考虑通过增强训练模型的隐私性来保护整个客户端数据集，而不是只保留单个数据条目。中心模型wt受到高斯噪声的扰动。[175]中的作者还应用GDP来保护fedag和FedSGD算法上的深度语言模型的隐私。[^174]、[^175]均表明，当本地客户端数量较大时，训练后的FL模型的隐私性可以达到更好的准确性。

中[^176]提出的方法通过高斯噪声的GDP技术扰动局部信息。他们还提供了一个K-client随机调度策略来选择用户进行FL模型训练。在Noisy-FL[^177]中，利用隐私跟踪框架f-DP[^58]来精确跟踪隐私丢失，在全局模型上采用基于gdp的PPAgg协议来解决[^174]、[^175]中需要大量客户端的限制，采用高斯机制。[^178]中的作者在异构物联网环境中设计了个性化PPFL模型。他们的模型可以实现$L2$灵敏度的$(\epsilon,\delta)-DP$(;通过在每次迭代过程中向全局模型中加入高斯噪声。他们假设退出的用户可以在不干扰正常训练过程的情况下重新加入模型训练。



## Blockchain-based Aggregation

区块链的特性允许将信任从单个服务器分发到一组区块链节点，从而提供对单点故障的弹性。在这种情况下，通常需要一个任务发布者来初始化全局FL模型。同时区块链保证了区块链中处理的数据和操作的可审计性和参与者的匿名性。FL中典型的基于区块链的聚合协议的工作原理如下：

(i)任务发布者将具有初始化全局模型的FL训练任务发布到区块链，然后(ii)每个FL用户获取全局模型，(iii)训练其本地模型。之后(iv)每个FL用户生成并广播一个记录其本地模型的事务，该事务将被节点接收并存储在其事务池中，然后(v)当选的共识节点将这些本地模型聚合起来，**通过共识协议获得全局模型**。最后，(vi)将新的全局模型包含在附加到区块链的块中，用于下一轮FL训练。

![image-20231027161336805](assets\综述文件\image-20231027161336805.png)

**Integeration of PPTs.**需要注意的是，在FL中，标准区块链无法防止模型聚合过程中的信息泄露，因为用户上传到区块链的模型仍然是明文的。因此，额外的ppt被认为是集成的，以实现基于区块链的PPAgg协议。

例如[^29]、[^191]、[^192]、[^193]采用CDP方法，[^194]、[^195]、[^196]采用LDP方法，在上传前对用户模型进行扰动。Paillier密码系统应用于[^197]，[^198]，[^199]与M1设置中的标准版本，或M3设置中的阈值版本[^200])。然而，关于密钥管理的安全问题仍然存在，即在采用的加密系统中使用的密钥所有权的安排。因此，一些研究旨在引入第三方作为助手。例如，在[^201]中，任务发布者和第三方拥有密钥对(pk1;Sk1)和(pk1;分别sk1)。它们合作生成一个公钥pk3, pk3加密的消息可以通过某种方式使用sk2转换，即重新加密为pk1加密的消息。在这种情况下，FL用户使用公钥pk3加密他们的模型，并通过区块链将它们发送给第三方，在那里执行重新加密和聚合。因此，只要任务发布者和第三方不串通，安全性就可以得到保证。除了上述通过区块链上传或记录用户模型的工作外，还有一些研究旨在利用区块链存储现有PPAgg协议的中间材料以进行可审计性。例如，[^202]和[^203]依赖于SecAgg协议[^33]，其中涉及的秘密密钥使用区块链共享和存储。

**Smart contract.** 除了集成隐私保护技术在区块链上提供隐私保障外，还可以采用智能合约进一步提高聚合的安全性或效率。例如，基于he的PPAgg协议[^204]，[^66]和[^205]额外利用智能合约来生成密钥对(pk;Sk)，其中公钥pk用于加密用户模型，秘钥sk传递给可信方[^206]，可以是由区块链共识协议[^204]选出的领导者，或智能合约中的密钥管理器[^66]，[^205]。这些关于密钥管理的方案类似于4.2节讨论的M1设置，但是安全风险被分配到区块链节点，并且通过使用智能合约降低了合谋风险。













[^25]:C. Fang, Y. Guo, Y. Hu, B. Ma, L. Feng, and A. Yin, “Privacypreserving and communication-efficient federated learning in internet of things,” Computers & Security, vol. 103, p. 102199, 2021.
[^33]:K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for privacy-preserving machine learning,” inproceedings of the 2017 ACM SIGSAC Conference on Computer andCommunications Security, 2017, pp. 1175–1191.

[^39]:P. Paillier, “Public-key cryptosystems based on composite degree residuosity classes,” in International conference on the theory and applications of cryptographic techniques. Springer, 1999.
[^40]:T. ElGamal, “A public key cryptosystem and a signature scheme based on discrete logarithms,” IEEE transactions on information theory, vol. 31, no. 4, pp. 469–472, 1985.
[^41]:J. H. Cheon, A. Kim, M. Kim, and Y. Song, “Homomorphic encryption for arithmetic of approximate numbers,” in International Conference on the Theory and Application of Cryptology and Information Security. Springer, 2017, pp. 409–437.
[^42]:H. Tian, C. Zeng, Z. Ren, D. Chai, J. Zhang, K. Chen, and Q. Yang, “Sphinx: Enabling privacy-preserving online learning over the cloud,” in 2022 2022 IEEE Symposium on Security and Privacy (SP),2022.
[^43]:D. Rotaru, N. P. Smart, T. Tanguy, F. Vercauteren, and T. Wood, “Actively secure setup for spdz,” Journal of Cryptology, vol. 35,no. 1, pp. 1–32, 2022.
[^44]:T. Nishide and K. Sakurai, “Distributed paillier cryptosystem without trusted dealer,” in International Workshop on Information Security Applications. Springer, 2010, pp. 44–60.
[^45]:C. Mouchet, J. R. Troncoso-Pastoriza, and J.-P. Hubaux, “Multiparty homomorphic encryption: From theory to practice.” IACR Cryptol. ePrint Arch., vol. 2020, p. 304, 2020.
[^16]:A. C. Yao, “Protocols for secure computations,” in 23rd annual symposium on foundations of computer science (sfcs 1982). IEEE,1982, pp. 160–164.
[^46]:P. Bogetoft, D. L. Christensen, I. Damgard, M. Geisler, T. Jakob- sen, M. Krøigaard, J. D. Nielsen, J. B. Nielsen, K. Nielsen, J. Pagter et al., “Secure multiparty computation goes live,” in International Conference on Financial Cryptography and Data Security. Springer,2009, pp. 325–343.
[^47]:D. Bogdanov, S. Laur, and J. Willemson, “Sharemind: A framework for fast privacy-preserving computations,” in European Symposium on Research in Computer Security. Springer, 2008.
[^48]:D. Demmler, T. Schneider, and M. Zohner, “Aby-a framework for efficient mixed-protocol secure two-party computation.” in NDSS, 2015.
[^49]:I. Damgard, V. Pastro, N. Smart, and S. Zakarias, “Multiparty computation from somewhat homomorphic encryption,” in Annual Cryptology Conference. Springer, 2012, pp. 643–662.
[^50]:P. Mohassel and P. Rindal, “Aby3: A mixed protocol framework for machine learning,” in Proceedings of the 2018 ACM SIGSAC conference on computer and communications security, 2018.
[^51]:P. Mohassel and Y. Zhang, “Secureml: A system for scalable privacy-preserving machine learning,” in 2017 IEEE symposium on security and privacy (SP). IEEE, 2017, pp. 19–38.
[^52]:S. Wagh, D. Gupta, and N. Chandran, “Securenn: 3-party secure computation for neural network training.” Proc. Priv. Enhancing Technol., vol. 2019, no. 3, pp. 26–49, 2019.
[^53]:M. Byali, H. Chaudhari, A. Patra, and A. Suresh, “Flash: fast and robust framework for privacy-preserving machine learning,”
Proceedings on Privacy Enhancing Technologies, 2020.

[^54]:H. Chaudhari, R. Rachuri, and A. Suresh, “Trident: Efficient 4pc framework for privacy preserving machine learning,” arXiv preprint arXiv:1912.02631, 2019.
[^66]:X. Wu, Z. Wang, J. Zhao, Y. Zhang, and Y. Wu, “Fedbc:blockchain-based decentralized federated learning,” in 2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA). IEEE, 2020, pp. 217–221.
[^65]:G. Wood et al., “Ethereum: A secure decentralised generalised transaction ledger,” Ethereum project yellow paper, 2014.
[^74]:Y. Zheng, S. Lai, Y. Liu, X. Yuan, X. Yi, and C. Wang, “Aggregation service for federated learning: An efficient, secure, and more resilient realization,” IEEE Transactions on Dependable and Secure Computing, 2022.
[^75]:P. Kairouz, Z. Liu, and T. Steinke, “The distributed discrete gaussian mechanism for federated learning with secure aggregation,” in International Conference on Machine Learning. PMLR, 2021.
[^76]:K. Bonawitz, F. Salehi, J. Konecnˇ y, B. McMahan, and M. Gruteser, “Federated learning with autotuned communication-efficient secure aggregation,” in 2019 53rd Asilomar Conference on Signals,Systems, and Computers. IEEE, 2019, pp. 1222–1226.
[^77]:R. Schlegel, S. Kumar, E. Rosnes et al., “Codedpaddedfl and codedsecagg: Straggler mitigation and secure aggregation in federated learning,” arXiv preprint arXiv:2112.08909, 2021.
[^78]:A. R. Elkordy and A. S. Avestimehr, “Heterosag: Secure aggregation with heterogeneous quantization in federated learning,” IEEE Transactions on Communications, 2022.
[^79]:I. Ergun, H. U. Sami, and B. Guler, “Sparsified secure aggregation for privacy-preserving federated learning,” arXiv preprint arXiv:2112.12872, 2021.
[^80]:J. Cui, C. Chen, T. Ye, and L. Wang, “Practical and light-weight secure aggregation for federated submodel learning,” arXiv preprint
[^81]:C. Niu, F. Wu, S. Tang, L. Hua, R. Jia, C. Lv, Z. Wu, and G. Chen, “Secure federated submodel learning,” arXiv preprint arXiv:1911.02254, 2019.
[^82]:J. So, B. Guler, and A. S. Avestimehr, “Turbo-aggregate: Breaking the quadratic aggregation barrier in secure federated learning,” IEEE Journal on Selected Areas in Information Theory, 2021.
[^83]:T. Jahani-Nezhad, M. A. Maddah-Ali, S. Li, and G. Caire, “Swiftagg: Communication-efficient and dropout-resistant secure aggregation for federated learning with worst-case security guarantees,” arXiv preprint arXiv:2202.04169, 2022.
[^84]:B. Choi, J.-y. Sohn, D.-J. Han, and J. Moon, “Communicationcomputation efficient secure aggregation for federated learning,”arXiv preprint arXiv:2012.05433, 2020.
[^85]:J. H. Bell, K. A. Bonawitz, A. Gascon, T. Lepoint, and M. Raykova, ´“Secure single-server aggregation with (poly) logarithmic overhead,” in Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security, 2020, pp. 1253–1269.
[^86]:K. Mandal, G. Gong, and C. Liu, “Nike-based fast privacypreserving highdimensional data aggregation for mobile devices,” IEEE T Depend Secure; Technical Report; University of Waterloo: Waterloo, ON, Canada, pp. 142–149, 2018.
[^87]:E. Shi, T. H. Chan, E. G. Rieffel, R. Chow, and D. Song, “Privacypreserving aggregation of time-series data,” in Proceedings of the Network and Distributed System Security Symposium, NDSS, 2011.
[^88]:Z. Jiang, W. Wang, and Y. Liu, “Flashe: Additively symmetric homomorphic encryption for cross-silo federated learning,” arXiv preprint arXiv:2109.00675, 2021.
[^89]:R. Wang, O. Ersoy, H. Zhu, Y. Jin, and K. Liang, “Feverless: Fast and secure vertical federated learning based on xgboost for decentralized labels,” 2021.
[^90]:J. Nguyen, K. Malik, H. Zhan, A. Yousefpour, M. Rabbat, M. Malek, and D. Huba, “Federated learning with buffered asynchronous aggregation,” arXiv preprint arXiv:2106.06639, 2021.
[^91]:J. So, C. He, C.-S. Yang, S. Li, Q. Yu, R. E. Ali, B. Guler, and S. Avestimehr, “Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning,” arXiv e-prints, pp.arXiv–2109, 2021.

[^92]:J. So, R. E. Ali, B. Guler, J. Jiao, and S. Avestimehr, “Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning,” arXiv preprint arXiv:2106.03328, 2021.

[^30]:Z. Liu, J. Guo, K.-Y. Lam, and J. Zhao, “Efficient dropout-resilient aggregation for privacy-preserving machine learning,” Accepted by IEEE Transactions on Information Forensics and Security,2022.
[^94]:Z. Liu, S. Chen, J. Ye, J. Fan, H. Li, and X. Li, “Efficient secure aggregation based on shprg for federated learning,” arXiv preprint arXiv:2111.12321, 2021.
[^72]:Y. Zhao and H. Sun, “Information theoretic secure aggregation with user dropouts,” in 2021 IEEE International Symposium on Information Theory (ISIT). IEEE, 2021, pp. 1124–1129.
[^95]:Y. Li, Y. Zhou, A. Jolfaei, D. Yu, G. Xu, and X. Zheng, “Privacypreserving federated learning framework based on chained secure multiparty computing,” IEEE Internet of Things Journal,vol. 8, no. 8, pp. 6178–6186, 2020.
[^96]:L. Ge, X. He, G. Wang, and J. Yu, “Chain-aafl: Chained adversarial-aware federated learning framework,” in International Conference on Web Information Systems and Applications.Springer, 2021, pp. 237–248.
[^97]:Q. Chen, Z. Wang, W. Zhang, and X. Lin, “Ppt: A privacypreserving global model training protocol for federated learning in p2p networks,” arXiv preprint arXiv:2105.14408, 2021.
[^98]:T. Sandholm, S. Mukherjee, and B. A. Huberman, “Safe: Secure aggregation with failover and encryption,” arXiv preprint arXiv:2108.05475, 2021.
[^100]:Y. Feng, X. Yang, W. Fang, S.-T. Xia, and X. Tang, “Practical and bilateral privacy-preserving federated learning,” 2020.
[^101]:K. Mandal and G. Gong, “Privfl: Practical privacy-preserving federated regressions on high-dimensional data over mobile networks,” in Proceedings of the 2019 ACM SIGSAC Conference on Cloud Computing Security Workshop, 2019, pp. 57–68.
[^102]:V. Mugunthan, A. Polychroniadou, D. Byrd, and T. H. Balch,“Smpai: Secure multi-party computation for federated learning,”in Proceedings of the NeurIPS 2019 Workshop on Robust AI in Financial Services, 2019.
[^103]:G. Xu, H. Li, S. Liu, K. Yang, and X. Lin, “Verifynet: Secure and verifiable federated learning,” IEEE Transactions on Information Forensics and Security, vol. 15, pp. 911–926, 2019.
[^104]:G. Han, T. Zhang, Y. Zhang, G. Xu, J. Sun, and J. Cao, “Verifiable and privacy preserving federated learning without fully trusted centers,” Journal of Ambient Intelligence and Humanized Computing,2021.
[^105]:X. Guo, Z. Liu, J. Li, J. Gao, B. Hou, C. Dong, and T. Baker, “Veri fl: Communication-efficient and fast verifiable aggregation for federated learning,” IEEE Transactions on Information Forensics and Security, vol. 16, pp. 1736–1751, 2020.
[^106]:C. Hahn, H. Kim, M. Kim, and J. Hur, “Versa: Verifiable secure aggregation for cross-device federated learning,” IEEE Transactions on Dependable and Secure Computing, 2021.
[^107]:L. Burkhalter, H. Lycklama, A. Viand, N. Kuchler, and A. Hithnawi, “Rofl: Attestable robustness for secure federated learning,”arXiv preprint arXiv:2107.03311, 2021.



[^108]:Y. Aono, T. Hayashi, L. Wang, S. Moriai et al., “Privacy-preserving deep learning via additively homomorphic encryption,” IEEE Transactions on Information Forensics and Security, 2017.
[^109]:Y. Dong, X. Chen, L. Shen, and D. Wang, “Eastfly: Efficient and secure ternary federated learning,” Computers & Security, 2020.
[^110]:F. Chen, P. Li, and T. Miyazaki, “In-network aggregation for privacy-preserving federated learning,” in 2021 International Conference on Information and Communication Technologies for Disaster Management (ICT-DM). IEEE, 2021, pp. 49–56.
[^111]:C. Zhou, A. Fu, S. Yu, W. Yang, H. Wang, and Y. Zhang, “Privacypreserving federated learning in fog computing,” IEEE Internet of Things Journal, vol. 7, no. 11, pp. 10 782–10 793, 2020.
[^112]:X. Zhang, A. Fu, H. Wang, C. Zhou, and Z. Chen, “A privacypreserving and verifiable federated learning scheme,” in ICC 2020-2020 IEEE International Conference on Communications (ICC).IEEE, 2020, pp. 1–6.
[^114]:R. Xu, N. Baracaldo, Y. Zhou, A. Anwar, J. Joshi, and H. Ludwig, “Fedv: Privacy-preserving federated learning over vertically partitioned data,” in Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security, 2021, pp. 181–192.

[^118]:C. Zhang, S. Li, J. Xia, W. Wang, F. Yan, and Y. Liu, “Batchcrypt: Efficient homomorphic encryption for cross-silo federated learning,” in 2020 USENIX Annual Technical Conference, USENIX ATC,A. Gavrilovska and E. Zadok, Eds., 2020.
[^119]:M. Asad, A. Moustafa, and T. Ito, “Fedopt: Towards communication efficiency and privacy preservation in federated learning,”Applied Sciences, vol. 10, no. 8, p. 2864, 2020.
[^120]:J. Guo, Z. Liu, K.-Y. Lam, J. Zhao, and Y. Chen, “Privacyenhanced federated learning with weighted aggregation,” in International Symposium on Security and Privacy in Social Networks
and Big Data. Springer, 2021, pp. 93–109.
[^121]:S. Zhang, Z. Li, Q. Chen, W. Zheng, J. Leng, and M. Guo, “Dubhe:Towards data unbiasedness with homomorphic encryption in federated learning client selection,” in 50th International Conference on Parallel Processing, 2021, pp. 1–10.
[^122]:A. B. Alexandru and G. J. Pappas, “Private weighted sum aggregation for distributed control systems,” IFAC-PapersOnLine,vol. 53, no. 2, pp. 11 081–11 088, 2020.
[^123]:D. Stripelis, H. Saleem, T. Ghai, N. Dhinagar, U. Gupta, C. Anastasiou, G. Ver Steeg, S. Ravi, M. Naveed, P. M. Thompson et al.,“Secure neuroimaging analysis using federated learning with homomorphic encryption,” in 17th International Symposium on Medical Information Processing and Analysis. SPIE, 2021.
[^117]:D. Xu, S. Yuan, and X. Wu, “Achieving differential privacy in vertically partitioned multiparty learning,” in 2021 IEEE International Conference on Big Data (Big Data). IEEE, 2021, pp. 5474–5483.
[^116]:W. Yang, B. Liu, C. Lu, and N. Yu, “Privacy preserving on updated parameters in federated learning,” in Proceedings of the ACM Turing Celebration Conference-China, 2020, pp. 27–31.
[^125]:S. Hardy, W. Henecka, H. Ivey-Law, R. Nock, G. Patrini, G. Smith, and B. Thorne, “Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption,” arXiv preprint arXiv:1711.10677, 2017.
[^126]:D. Gao, Y. Liu, A. Huang, C. Ju, H. Yu, and Q. Yang, “Privacypreserving heterogeneous federated transfer learning,” in 2019 IEEE International Conference on Big Data (Big Data). IEEE, 2019.
[^127]:Y. Liu, Y. Kang, C. Xing, T. Chen, and Q. Yang, “A secure federated transfer learning framework,” IEEE Intelligent Systems,vol. 35, no. 4, pp. 70–82, 2020.
[^128]:J. Zhang, B. Chen, S. Yu, and H. Deng, “Pefl: A privacy-enhanced federated learning scheme for big data analytics,” in 2019 IEEE Global Communications Conference (GLOBECOM). IEEE, 2019.
[^129]:M. Asad, A. Moustafa, and M. Aslam, “Ceep-fl: A comprehensive approach for communication efficiency and enhanced privacy in federated learning,” Applied Soft Computing, 2021.
[^130]:H. Zhu, R. Wang, Y. Jin, and K. Liang, “Pivodl: Privacypreserving vertical federated learning over distributed labels,”IEEE Transactions on Artificial Intelligence, 2021.
[^131]:S. Truex, N. Baracaldo, A. Anwar, T. Steinke, H. Ludwig,R. Zhang, and Y. Zhou, “A hybrid approach to privacypreserving federated learning,” in Proceedings of the 12th ACM workshop on artificial intelligence and security, 2019, pp. 1–11.
[^132]:Y. Liu, Z. Ma, X. Liu, S. Ma, S. Nepal, R. H. Deng, and K. Ren,“Boosting privately: Federated extreme gradient boosting for mobile crowdsensing,” in 2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS). IEEE, 2020, pp. 1–11.
[^133]:Y. Li, H. Li, G. Xu, X. Huang, and R. Lu, “Efficient privacypreserving federated learning with unreliable users,” IEEE Internet of Things Journal, 2021.
[^134]:J. Ma, S.-A. Naas, S. Sigg, and X. Lyu, “Privacy-preserving federated learning based on multi-key homomorphic encryption,”International Journal of Intelligent Systems, 2022.
[^135]:Z. L. Jiang, H. Guo, Y. Pan, Y. Liu, X. Wang, and J. Zhang, “Secure neural network in federated learning with model aggregation under multiple keys,” in 2021 8th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2021 7th IEEE International Conference on Edge Computing and Scalable Cloud(EdgeCom). IEEE, 2021, pp. 47–52.
[^136]:W. Zheng, R. A. Popa, J. E. Gonzalez, and I. Stoica, “Helen: Maliciously secure coopetitive learning for linear models,” in 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019.
[^137]:H. Zhu, R. Wang, Y. Jin, K. Liang, and J. Ning, “Distributed additive encryption and quantization for privacy preserving federated deep learning,” Neurocomputing, 2021.
[^138]:H. Tian, F. Zhang, Y. Shao, and B. Li, “Secure linear aggregation using decentralized threshold additive homomorphic encryption for federated learning,” arXiv preprint arXiv:2111.10753, 2021.
[^93]:R. Nasirigerdeh, R. Torkzadehmahani, J. Matschinske, J. Baumbach, D. Rueckert, and G. Kaissis, “Hyfed: A hybrid federated framework for privacy-preserving machine learning,” arXiv preprint arXiv:2105.10545, 2021.

[^147]:S. Kadhe, N. Rajaraman, O. O. Koyluoglu, and K. Ramchandran, “Fastsecagg: Scalable secure aggregation for privacy-preserving federated learning,” arXiv preprint arXiv:2009.11248, 2020.



