# 隐私保护联邦学习的综合调查:分类、回顾和未来方向

## A Comprehensive Survey of Privacy-preserving Federated Learning: A Taxonomy, Review, and Future Directions

### | PPML methods

- homomorphic encryption(HE) based PPML           
- secure multi-party computation-(SMC) based PPML
- differential privacy(DP) based PPML

---

### | Main Contributions

我们提出了一种基于5w场景的分类方法，系统地分析了PPFL的潜在隐私泄露风险，从而为PPFL提供了一个全面的、多维的图像。

建议的基于5w场景的分类法涉及五个基本方面:“谁”(内部和外部攻击者)、“什么”(主动和被动攻击)、“何时”(训练和推理阶段)、“在哪里”(权重更新、梯度更新和最终模型)和“为什么”(四种类型的推理攻击)。

• 我们根据我们分类的四种隐私保护机制总结了最先进的PPFL方法，为未来的研究调查提供了重要的指导。提出的PPFL类别包括:<u>基于加密的、基于扰动的、基于匿名的和混合PPFL</u>。

• 我们提供了一个明确的概述和一般的隐私保护机制，为PPFL及其应用的未来研究铺平道路。FL的分类基于数据划分和通信体系结构。从隐私保护技术和隐私保护度量两个方面介绍了通用的隐私保护机制。

• 我们讨论了PPFL的挑战，澄清了现有的差距，确定了开放的研究问题，并指出了未来的研究方向。

### | OVERVIEW OF GENERIC PRIVACY-PRESERVING MECHANISMS

通用隐私保护机制概述

- Cryptographic Techniques

同态加密、秘密分享、安全多方计算SMC

SMC[207]是一种加密方案，它使分布式参与者能够在不泄露其数据的情况下协作计算目标函数。形式上，n个参与者{P1, P2，…， Pn}旨在计算一个全局函数f (D1, D2，…)， Dn)基于每个人的数据集Di。如果协议满足以下两个要求，则称其为SMC协议[98]:(1)正确性，其中函数f (D1, D2，…(2)隐私性，即协议不向任何其他参与者透露Dn的任何隐私信息。

它的优点是:(1)不需要可信的第三方，(2)消除了数据效用和数据隐私之间的权衡，(3)实现了较高的准确性。缺点是计算开销和高通信成本

-  Perturbation Techniques

微扰技术的关键思想是在原始数据中加入噪声，使从受扰动数据中计算出的统计信息在统计上与原始数据无法区分。有三种类型的微扰技术被广泛使用:微分隐私，加性微扰和乘性微扰

加性摄动的目的是通过加入一定分布(如均匀分布或高斯分布)的随机噪声来保护原始数据的隐私，其表达式为Y = X + δ，其中Y表示被摄动的数据，$x \in R^{d*n}$表示原始数据，$δ∈R^{d*n}$表示随机噪声[4]。该技术简单，可以保持统计特性[86]。但是，它可能会降低数据效用，并且可能容易受到噪声降低的影响。

乘法摄动的目的是使用来自一定分布的噪声对原始数据进行乘法[25]。乘法摄动的目的不是在原始数据中加入一些随机噪声，而是将原始数据点变换到一定的空间中[108]。与加性摄动相比，乘性摄动更有效，因为从乘性摄动的摄动数据重构原始数据更加困难[50]。

- Anonymization Techniques(匿名化技术)

匿名化技术主要用于实现基于组的匿名化，方法是在保留已发布数据的实用性的同时删除可识别信息。有三种广泛使用的匿名化技术:k-匿名、l-多样性和t-接近。

科普网站(k、l、t)：https://www.secrss.com/articles/28748

- Privacy-preserving Metrics

有两种类型的指标被广泛用于评估隐私保护方法的性能:(1)用于测量数据集隐私损失的**隐私**指标;(2)用于测量用于数据分析目的的受保护数据的数据效用的**效用**指标[171]。

隐私指标旨在衡量隐私保护技术的隐私损失[180]。Wager等人[181]全面回顾了80多个隐私指标，并从4个常见方面讨论了这些指标:对手模型、数据源、指标计算的输入和输出度量。例如，攻击者模型从攻击者的角度分析功能和目标，数据源从数据源的角度引入隐私泄露问题。通常，特定情况的隐私度量由许多方面决定，例如输入、数据源和对手模型。在大多数情况下，单一指标可能无法完全评估完整的隐私。

效用指标旨在量化受隐私保护技术保护的数据的效用，用于数据分析目的，即一般分析目的和特定分析目的[55]。为了进行一般分析，定义了信息丢失度量来衡量原始数据与被保护数据之间的相似度[23]。它们通常由受保护数据保留原始数据统计信息的程度来衡量。对于特定的分析目的(例如，机器学习和统计分析任务)，通过比较使用受保护数据和原始数据的任务的评估准确性来测量数据效用。

---

###  Potential Privacy Leakage Risks in FL

在本节中，我们将从五个基本方面对FL中潜在的隐私泄露风险进行全面分析。

#### Who

谁可能是恶意的对手?内部人士和外部人士。在FL中，有两种类型的参与者可以访问模型信息:内部参与者(参与的客户端和中央服务器)和外部参与者(模型消费者和窃听者)。

客户端或服务器都有机会访问中间训练更新(例如，权重和梯度)和最终模型。因此，某些<u>参与者和诚实但好奇的服务器</u>可能是潜在的内部恶意对手，其目标是获得对私人数据的访问权。

另一种类型的潜在恶意对手可能来自外部参与者:<u>模型消费者或窃听者</u>。模型消费者通常有两种方法来探测私有数据。首先，他们可以获得对整个模型权值的访问，其次，他们可以获得由平台API提供的访问查询结果[175]。因此，他们可以通过最终模型或其查询结果来探测私有数据。与模型消费者可以正式且轻松地访问最终模型相比，窃听者可以通过拦截参与者与服务器之间的通信窃取中间训练更新或最终模型[187]。然而，这种窃听过程通常需要更多的努力。此外，窃听者可能窃取参与者与聚合器之间传输的中间权重或梯度[29]。因此，某些模型消费者和窃听者可能是潜在的外部对手。

#### What types of privacy attacks?

被动和主动攻击。根据RFC 4949[159]，<u>被动攻击</u>被定义为旨在利用信息或从系统中学习而不修改系统的攻击，而主动攻击被定义为旨在改变系统资源或影响系统运行的攻击。对于FL，被动攻击者只在训练和推理阶段观察计算(例如，权重、梯度和最终模型)[123,228]，而<u>主动攻击</u>者可以通过操纵模型参数来影响FL系统，以实现敌对目标。

FL中的被动攻击可分为被动黑盒攻击和被动白盒攻击两大类。在被动黑箱攻击中，例如，在服务平台的设置中，假设攻击者只能访问查询结果，而不能访问模型参数或中间训练更新。Nasr等[129]针对隶属推理对这种攻击进行了研究。在被动白盒攻击中，假设攻击者可以访问中间训练更新、模型参数和查询结果[129]。

例如，Melis等人[123]设计了一种主动攻击，攻击者将一个特殊的梯度上传到全局模型中以学习可分离表征。Song等人[165]通过隔离某些客户端，从恶意服务器的角度提出了主动攻击。此外，Xu等人[200]提出了一种主动攻击，通过控制某些客户端策略性地调整训练数据，使全局模型以特殊的模式上升或下降。

#### When

何时可能发生数据隐私泄露?训练阶段和推理阶段。

对于FL，有两个主要阶段:<u>训练阶段和</u><u>推理阶段</u>。训练阶段主要包括在客户端计算局部梯度，在服务器端聚合全局模型，在客户端和聚合器之间传递中间更新，并将最终模型发布给客户端[69,96]。推理阶段主要涉及向消费者<u>提供查询服务的方法</u>[129]。这两个阶段都容易受到隐私泄露的影响。

#### Where

数据隐私泄露可能发生在哪里?<u>权重更新</u>，梯度更新，<u>最后的模型</u>。使用FL，参与者和聚合器之间需要传输三种类型的重要数据:局部权重/梯度、聚合的权重/梯度和最终模型，所有这些数据都包含必要的信息，可以用来揭示关于训练数据集的敏感信息[53,212]。在基于梯度/权重更新的FL框架中，客户端将梯度/权重发送给服务器;服务器聚合接收到的数据并将其发送回客户端进行模型更新[107,115]。在深度网络模型中，梯度通常是通过在整个网络中反向传播训练数据集的损失来计算的。具体来说，一层的梯度是利用当前层的数据特征和来自上层的误差来计算的。同样，基于参与者的本地数据集计算本地模型权重。因此，它们(权重更新、梯度更新和最终模型)包含了局部数据的敏感信息[133,142,167]。FL中的最终模型由多个参与者的私有数据集协同训练，并编码这些数据集的基本信息[53]

#### Why

为什么恶意攻击者会发起攻击?推理攻击，包括类代表的推理、隶属关系、训练数据的属性、训练样本和标签。隐私攻击的目的通常是推断有关训练数据集的敏感信息，例如成员和类代表。推理攻击可分为四类：class representatives, memberships, properties of training data, and training samples and labels

•类代表的推断旨在生成代表性样本，这些样本不是训练数据集的真实数据实例，但可用于研究训练数据集相关的敏感信息。

•成员资格推断旨在确定数据样本是否已用于模型训练，是否包含在训练数据样本中。

•训练数据属性的推断旨在推断与训练数据集相关的属性信息。

•推断<u>训练样本和标签旨</u>在重建原始训练数据样本和相应标签。

