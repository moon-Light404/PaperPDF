# Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure Federated Learning

## Abstract


将联邦学习扩展到大量用户的一个主要瓶颈是跨许多用户进行安全模型聚合的开销。特别是，用于安全模型聚合的最先进协议的开销随着用户数量呈二次增长。在本文中，我们提出了第一个名为Turbo-Aggregate的安全聚合框架，该框架在有N个用户的网络中实现了$O(NlogN)$的安全聚合开销，而不是$O(n^2)$，同时允许高达50%的用户辍学率。Turbo-Aggregate采用**多组循环策略进行高效的模型聚合**，**并利用加性秘密共享和新颖的编码技术注入聚合冗余，在保证用户隐私的同时处理用户退出**。我们通过实验证明，Turbo-Aggregate实现了与用户数量几乎呈线性增长的总运行时间，并且与最多$N=200$个用户的最先进协议相比，提供了高达40倍的加速。我们的实验也证明了模型大小和带宽对Turbo-Aggregate性能的影响。


索引术语:联邦学习、保护隐私的机器学习、安全聚合。



安全模型聚合的开销是将安全联邦学习扩展到大量用户的主要瓶颈